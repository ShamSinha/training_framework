# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/tfsm/10_voxt.ipynb.

# %% auto 0
__all__ = ['Norm3d', 'pad3d', 'pad3d_by_rsize', 'pad3d_by_div', 'PadIfNeeded', 'Transpose', 'get_valid_centers', 'volume',
           'vol_intersect', 'remove_out_of_bounds_bboxes', 'clip_2_img', 'crop_bbox', 'calculate_occupancy',
           'random_crop', 'select_min_overlap_cuboids', 'generate_end_biased_distribution', 'random_crop_multi',
           'random_crop_img', 'RandPosCrop', 'ApplyWindowsChannelWise', 'ToNumpy']

# %% ../../nbs/tfsm/10_voxt.ipynb 3
import numpy as np
import fastcore.all as fc
from typing import Union, Tuple, List
from .standard import BaseT
from .utils import corner_2_chwd, chwd_2_corner
from ..bbox_func.bbox_iou import calculate_iou
import math
from loguru import logger

# %% ../../nbs/tfsm/10_voxt.ipynb 6
class Norm3d(BaseT):
    def __init__(self, a_min:float, a_max:float, b_min:float=None, b_max:float=None, clip:bool=True, renorm:bool=False): 
        super().__init__()
        fc.store_attr()
    __repr__ = fc.basic_repr(flds="a_min, a_max, b_min, b_max, clip")
    
    def apply(self, img:dict):
        assert "images" in img.keys(), "images key is not present"
        fimg = img["images"]
        nimg = {}
        nimg["images"] = self.apply_image(fimg)
        for i in img.keys(): 
            if i not in nimg.keys(): nimg[i] = img[i]
        return nimg 
    
    def apply_image(self, img):
        if self.a_max - self.a_min == 0.0: 
            logger.warning("Divide by zero (a_min == a_max)")
            if self.b_min is None: return img - self.a_min
            return img - self.a_min + self.b_min 
        img = (img - self.a_min) / (self.a_max - self.a_min)
        if (self.b_min is not None) and (self.b_max is not None):
            img = img * (self.b_max - self.b_min) + self.b_min
        if self.clip:
            img = np.clip(img, self.b_min, self.b_max)
        if self.renorm:
            img = 2*img - 1 # renormalize the image from [-1, 1]
        return img.astype(np.float32)
    
    def reverse_apply(self, img: dict): return img

# %% ../../nbs/tfsm/10_voxt.ipynb 15
def pad3d(img: np.ndarray, bbox: np.ndarray, pad:Union[int, Tuple[int]], side="both"):
    """img is [zyxzyx], bbox[zyx] pad[zyx]
    Pads the image in all direction. we usually gets twice the size of the asked padding.
    side takes "left" "right" "both" values
    """
    if side not in ["left", "right", "both"]: raise NotImplementedError(f"side cannot be {side}")
    
    pad = (pad,)*3 if isinstance(pad, int) else pad
    n = 2 if side == "both" else 1
    
    multi_view = len(img.shape) == 4
    img_shape = img.shape[1:] if multi_view else img.shape
    pimg = np.zeros(np.asarray(img_shape) + n*np.asarray(pad))
    if multi_view:
        pimg = np.expand_dims(pimg, axis=0)
        pimg = np.repeat(pimg, img.shape[0], axis=0)
    
    if side == "right": pad = (0, 0, 0)
    ims = np.asarray(img_shape) + np.asarray(pad)
    if multi_view:
        pimg[:, pad[0]:ims[0], pad[1]:ims[1], pad[2]:ims[2]] = img
    else:
        pimg[pad[0]:ims[0], pad[1]:ims[1], pad[2]:ims[2]] = img
    
    if bbox is None: return pimg 
    pbbox = bbox + np.asarray(tuple(pad)+tuple(pad))
    return pimg, pbbox

# %% ../../nbs/tfsm/10_voxt.ipynb 30
def pad3d_by_rsize(img: np.ndarray, bbox: np.ndarray, rsize: Tuple[int], side="symmetric"):
    """img is [zyxzyx], bbox[zyx] crop[zyx]"""
    img_shape = img.shape[1:] if len(img.shape) == 4 else img.shape
    pad_shape = np.maximum(np.asarray(rsize) - np.asarray(img_shape), 0)
    if side != "symmetric": return pad3d(img, bbox, pad_shape.astype(int), side=side)
    both_pad = np.floor(pad_shape/2).astype(int)
    right_pad = pad_shape%2
    if bbox is None:
        bimg = pad3d(img, None, both_pad, side="both")
        rimg = pad3d(bimg, None, right_pad, side="right")
        return rimg
    bimg, bbbox = pad3d(img, bbox, both_pad, side="both")
    rimg, rbbox = pad3d(bimg, bbbox, right_pad, side="right")
    return rimg, rbbox

# %% ../../nbs/tfsm/10_voxt.ipynb 40
def pad3d_by_div(img: np.ndarray, bbox: np.ndarray, size_divisible: int=4, side: str= "symmetric"):
    """img is [zyxzyx], bbox[zyx] set the final img dim should be divisible by {size_divisible}"""
    img_shape = img.shape[1:] if len(img.shape) == 4 else img.shape
    new_shape = (np.ceil(np.asarray(img_shape)/size_divisible)*size_divisible).astype(int)
    return pad3d_by_rsize(img, bbox, new_shape, side)

# %% ../../nbs/tfsm/10_voxt.ipynb 45
class PadIfNeeded(BaseT):
    def __init__(self, sd=None, img_size=None, side: str="right"):
        """sd is size divisible, img_size in zyx format. One of it should be None"""
        fc.store_attr()
        super().__init__()
        assert self.side in ["right"], "only right side is implemented"
        if (self.sd is None) and (self.img_size is None): raise ValueError("Both intputs sd and img_size cant be None")
        if None not in (self.sd, self.img_size): raise ValueError("One of sd or img_size should be None. Both are given")
    
    __repr__ = fc.basic_repr("sd, img_size, side")
    
    def apply(self, img: dict):
        assert "images" in img.keys(), f"images not present in input [img]. Only: {img.keys()} present"
        fimg = img["images"].copy()
        bbox = img["boxes"].copy() if "boxes" in img.keys() else None
        nimg = {}
        out = pad3d_by_div(fimg, bbox, self.sd, self.side) if self.sd is not None else pad3d_by_rsize(fimg, bbox, self.img_size, self.side)
        if bbox is None: nimg["images"] = out
        else: nimg["images"], nimg["boxes"] = out
        for i in img.keys():
            if i not in nimg.keys(): nimg[i] = img[i]
        return nimg
    
    def reverse_apply(self, img: dict): 
        if self.side != "right": raise ValueError("only right allowed")
        return img 

# %% ../../nbs/tfsm/10_voxt.ipynb 56
class Transpose(BaseT):
    def __init__(self, order: tuple= None):
        fc.store_attr()
        super().__init__()
        assert len(order) ==3, f"only order 3 is allowed for now. given: {self.order}"
        self.rorder = self.reverse_order()
        self.boxo = self.order + tuple([i+len(self.order) for i in self.order])
        self.boxro = self.rorder + tuple([i+len(self.rorder) for i in self.rorder])
    
    __repr__ = fc.basic_repr(flds="order")
    
    def apply(self,  img):
        if self.order is None: return img
        assert "images" in img.keys(), "images key not Present"
        fimg = img["images"].copy()
        assert len(self.order) == len(fimg.shape), f"order: {self.order} and img : {fimg.shape} is not same"
        nimg={}
        nimg["images"] = self.apply_img(fimg, self.order)
        if "boxes" in img.keys(): nimg["boxes"] = self.apply_bbox(img["boxes"], self.boxo)
        if "spacing" in img.keys(): nimg["spacing"] = [img['spacing'][i] for i in self.order]
        for i in img.keys():
            if i not in nimg.keys(): nimg[i] = img[i]
        return nimg
    
    def apply_img(self, img, order): return img.transpose(order)

    def apply_bbox(self, bbox, order):
        out = bbox.copy()
        out = out[:, order]
        return out 
    
    def reverse_apply(self, img: dict):
        assert "images" in img.keys()
        nimg = {}
        nimg["images"] = self.apply_img(img["images"], self.rorder)
        if "boxes" in img.keys(): nimg["boxes"] = self.apply_bbox(img["boxes"], self.boxro)
        if "spacing" in img.keys(): nimg["spacing"] = [img['spacing'][i] for i in self.rorder]
        for i in img.keys():
            if i not in nimg.keys(): nimg[i] = img[i]
        return nimg
    
    def reverse_order(self):
        o = "".join(map(lambda x: str(x), self.order))
        mapper = {"120": "201", "102": "102", "210": "210", "201": "120", "021": "021", "012": "012"}
        return tuple([int(i) for i in mapper[o]])

# %% ../../nbs/tfsm/10_voxt.ipynb 87
def get_valid_centers(base: np.ndarray, crop_size: Tuple[int], img_shape: Tuple[int]):
    """base: [z, y, z, z, y, x] crop_size: (z, y, x), img_size: (z, y, x)"""
    b1c = corner_2_chwd(base)[0]
    x = b1c[:3]- np.asarray(crop_size)/2
    y = b1c[:3]+ np.asarray(crop_size)/2
    # Remove all centers which are outside image 
    x = np.maximum(x, 0)
    y = np.minimum(y, img_shape)
    # we need to select boxes which are inside image 
    x = np.maximum(x, np.asarray(crop_size)/2)
    y = np.minimum(y, np.asarray(img_shape) - np.asarray(crop_size)/2)
    #cast to nearest int
    #x = np.floor(x).astype(int)
    #y = np.ceil(y).astype(int)
    x = np.ceil(x).astype(int)
    y = np.floor(y).astype(int)
    ctrs = np.mgrid[x[0]:y[0]+1:1, x[1]:y[1]+1:1, x[2]:y[2]+1:1].reshape(3, -1).T
    
    #calculate all the crops
    #ctrs2 = np.hstack([ctrs - np.asarray(crop_size)/2, ctrs + np.asarray(crop_size)/2])
    #now make sure that select base is which in the crop selected 
    #tt = calculate_iou_numpy(ctrs2, base)
    #ctrs = ctrs[tt.reshape(-1)>0]
    return ctrs , x ,y

# %% ../../nbs/tfsm/10_voxt.ipynb 99
def volume(box):
    """
    Calculate the volume of a box given in [z1, y1, x1, z2, y2, x2] format.
    """
    z1, y1, x1, z2, y2, x2 = box
    return abs((z1 - z2) * (y1 - y2) * (x1 - x2))

def vol_intersect(bbox, crop_box):
    """
    Calculate the volume of the intersection between two boxes.
    Each box is given in [z1, y1, x1, z2, y2, x2] format.
    """
    az1, ay1, ax1, az2, ay2, ax2 = bbox
    bz1, by1, bx1, bz2, by2, bx2 = crop_box
    
    z_overlap = max(0, min(az2, bz2) - max(az1, az1))
    y_overlap = max(0, min(ay2, by2) - max(ay1, ay1))
    x_overlap = max(0, min(ax2, bx2) - max(ax1, ax1))
    
    intersection_volume = z_overlap * y_overlap * x_overlap
    return intersection_volume

# %% ../../nbs/tfsm/10_voxt.ipynb 106
def remove_out_of_bounds_bboxes(bboxes, img_shape):
    z, y, x = img_shape 
    zmin, ymin, xmin, zmax, ymax, xmax = bboxes.T
    valid_index = np.where((zmin < z) & (ymin < y) & (xmin < x) & (zmax >= 0) & (ymax >= 0) & (xmax >= 0))
    return bboxes[valid_index]

# %% ../../nbs/tfsm/10_voxt.ipynb 111
def clip_2_img(bbox: np.ndarray, img_size: Tuple[int]):
    """remove all the boxes which have x2 or y2 or z2 as negative and are outside the img_size completely"""
    bbox = remove_out_of_bounds_bboxes(bbox, img_size)
    bbox[:, 0] = np.maximum(0, bbox[:, 0])  # x1
    bbox[:, 1] = np.maximum(0, bbox[:, 1])  # y1
    bbox[:, 2] = np.maximum(0, bbox[:, 2])  # y1
    bbox[:, 3] = np.minimum(img_size[0], bbox[:, 3])  # x2
    bbox[:, 4] = np.minimum(img_size[1], bbox[:, 4])  # x2
    bbox[:, 5] = np.minimum(img_size[2], bbox[:, 5])  # y2
    return bbox

# %% ../../nbs/tfsm/10_voxt.ipynb 113
def crop_bbox(bbox: np.ndarray, fb: np.ndarray, img_size: Tuple[int], keep_volume: float):
    """bbox is [zyxzyx] fb is [zyxzyx] and the img_size [zyx]"""
    if fb.shape != (6, ): raise ValueError(f"fb shape required is (6,). Got {fb.shape}")
    bbox_vol_overlap = np.array([vol_intersect(box, fb)/volume(box) for box in bbox])
    keep = bbox_vol_overlap >= keep_volume
    new_bbox = bbox[keep]
    bboxc = corner_2_chwd(new_bbox.astype(np.float32))
    fb = fb.astype(np.float32)
    bboxc[:, :3] -= fb[:3]
    nbbox = chwd_2_corner(bboxc)
    nbbox2 = clip_2_img(nbbox, img_size)
    return nbbox2

# %% ../../nbs/tfsm/10_voxt.ipynb 115
def calculate_occupancy(img_shape, crop_boxes):
    """
    Calculate the percentage of volume occupied by potentially overlapping
    smaller cuboids(crop_boxes) within a larger cuboid defined by an img_shape,
    
    Parameters:
    - img_shape: The shape of the image (z, y, x) defining the dimensions of the larger cuboid.
    - crop_boxes: coordinates in the format [z1, y1, x1, z2, y2, x2].
    
    Returns:
    - The percentage of the total volume of smaller cuboids relative to the volume of the larger cuboid.
    """
    voxels = np.zeros(img_shape, dtype=bool)
    
    for row in crop_boxes:
        z1, y1, x1, z2, y2, x2 = row
        voxels[z1:z2, y1:y2, x1:x2] = True
    
    occupied_volume = np.sum(voxels)
    larger_volume = np.prod(img_shape)
    
    vol_occupancy = (occupied_volume / larger_volume)
    return vol_occupancy

# %% ../../nbs/tfsm/10_voxt.ipynb 116
def random_crop(img: np.ndarray, bbox: np.ndarray, crop_size: Tuple[int], sample_size: int = 1, keep_volume: float = 0.5):
    """img: zyx crop_size: zyx bbox: [z, y, x, z, y, x]"""
    img_shape = img.shape if len(img.shape) == 3 else img.shape[1:]
    
    crops = []
    cboxes = []
    crop_corners = []
    
    if len(bbox) >= sample_size :
        select_indices = np.random.choice(len(bbox) , size = sample_size ,replace = False)
    else : 
        select_indices = np.random.choice(len(bbox) , size = sample_size)
                
    for i in select_indices :
        b1 = bbox[i][None]
        ctrs ,_ ,_ = get_valid_centers(b1, crop_size, img_shape)
        crop_center = ctrs[np.random.randint(len(ctrs))]

        x = crop_center - np.asarray(crop_size)/2
        y = crop_center + np.asarray(crop_size)/2
        fb = np.hstack([x, y]).astype(np.int32) #final crop box 
        
        crop_corners.append(fb)

        nimg = img[..., fb[0]:fb[3], fb[1]:fb[4], fb[2]:fb[5]]
        if (bbox is None) or (bbox.shape[0] == 0):
            nbbox = np.empty((0, 6))
        else:
            nbbox = crop_bbox(bbox, fb, crop_size, keep_volume)
        crops.append(nimg)  
        cboxes.append(nbbox)
        
    crop_occupancy = calculate_occupancy(img_shape , crop_corners)
    
    if len(crops) == 1 :
        return crops[0] , cboxes[0] , crop_occupancy
        
    return crops, cboxes , crop_occupancy


# %% ../../nbs/tfsm/10_voxt.ipynb 119
def select_min_overlap_cuboids(iou_matrix, M):
    N = iou_matrix.shape[0]  # Number of cuboids
    selected_indices = []  # Indices of selected cuboids
    
    for _ in range(M):
        # Calculate the average IOU of each cuboid with the already selected cuboids
        if selected_indices:
            avg_iou = np.mean(iou_matrix[selected_indices], axis=0)
        else:
            # If no cuboids have been selected yet, set initial avg_iou to favor first selection
            avg_iou = np.zeros(N)
        
        # Exclude already selected cuboids by setting their avg_iou to a high value
        avg_iou[selected_indices] = np.inf
        
        # Select the cuboid with the minimal average IOU
        next_index = np.argmin(avg_iou)
        selected_indices.append(next_index)
    
    return selected_indices

# %% ../../nbs/tfsm/10_voxt.ipynb 124
def generate_end_biased_distribution(length):
    """
    Generate a probability distribution with higher probabilities at the ends.
    
    Parameters:
    - length: The total length of the list.
    
    Returns:
    - A numpy array of probabilities.
    """
    # Create an array with indices from 0 to length - 1
    indices = np.arange(length)
    # Calculate the distance of each index from the nearest end
    distances = np.minimum(indices, length - 1 - indices)
    # Generate probabilities inversely related to the distance (higher near ends)
    probabilities = 1 /(1 + distances)
    # Normalize probabilities to sum to 1
    probabilities /= probabilities.sum()
    return probabilities

# %% ../../nbs/tfsm/10_voxt.ipynb 125
def random_crop_multi(img: np.ndarray, bbox: np.ndarray, crop_size: Tuple[int], sample_size: int, keep_volume: float = 0.5):
    """img: zyx crop_size: zyx bbox: [z, y, x, z, y, x]"""
    img_shape = img.shape if len(img.shape) == 3 else img.shape[1:]
    
    sample_per_bbox = math.ceil(sample_size/len(bbox))    
    crop_centers = []

    for j in range(len(bbox)) :
        b1 = bbox[j][None]
        _ , x, y = get_valid_centers(b1, crop_size, img_shape)
        A = np.arange(x[0],y[0]+1,1)
        B = np.arange(x[1],y[1]+1,1)
        C = np.arange(x[2],y[2]+1,1)
                
        if len(A) < sample_per_bbox :
            a = np.random.choice(A , sample_per_bbox)
        else :
            a = np.random.choice(A , sample_per_bbox, replace = False, p = generate_end_biased_distribution(len(A)))
        
        if len(B) < sample_per_bbox :
            b = np.random.choice(B , sample_per_bbox)
        else :
            b = np.random.choice(B , sample_per_bbox,replace = False,  p = generate_end_biased_distribution(len(B)))
            
        if len(C) < sample_per_bbox :
            c = np.random.choice(C , sample_per_bbox)
        else :
            c = np.random.choice(C , sample_per_bbox,replace =False,  p = generate_end_biased_distribution(len(C)))
            
        crop_ctrs = [[a[i] , b[i] , c[i]] for i in range(sample_per_bbox)]
        crop_centers.extend(crop_ctrs)
                 
    crop_corners = []
    for crop_center in crop_centers : 
        x = crop_center - np.asarray(crop_size)/2
        y = crop_center + np.asarray(crop_size)/2
        fb = np.hstack([x, y]).astype('int').tolist()
        crop_corners.append(fb)
        
    crop_corners = np.array(crop_corners)
    
        
    if len(crop_corners) > sample_size :
#         selected_indices = np.random.choice(len(crop_corners) ,size= sample_size ,replace=True)
#         crop_corners = crop_corners[selected_indices , :]
        overlaps = calculate_iou(crop_corners, crop_corners)
        np.fill_diagonal(overlaps, 0)
        selected_indices = select_min_overlap_cuboids(overlaps, sample_size)
        crop_corners = crop_corners[selected_indices , :]
        
    crop_occupancy = calculate_occupancy(img_shape , crop_corners)
         
    crops = []
    cboxes = []
    
    for fb in crop_corners :
        nimg = img[..., fb[0]:fb[3], fb[1]:fb[4], fb[2]:fb[5]]
        if (bbox is None) or (bbox.shape[0] == 0):
            nbbox = np.empty((0, 6))
        else:
            nbbox = crop_bbox(bbox, fb, crop_size, keep_volume)
                        
        crops.append(nimg)
        cboxes.append(nbbox)
    
    if len(crops) == 1 :
        return crops[0] , cboxes[0] , crop_occupancy
    
    return crops, cboxes, crop_occupancy

# %% ../../nbs/tfsm/10_voxt.ipynb 129
def random_crop_img(img, crop_size):
    img_shape = img.shape if len(img.shape) == 3 else img.shape[1:]
    if (np.asarray(crop_size) >= np.asarray(img_shape)).any(): img = pad3d_by_rsize(img, None, crop_size)
    lv = np.asarray(img_shape) - np.asarray(crop_size)
    y = [np.random.randint(i) if i>0 else 0 for i in lv]
    z1, y1, x1, z2, y2, x2 = tuple(y) + tuple(y+np.asarray(crop_size))
    assert (z2-z1, y2-y1, x2-x1) == tuple(crop_size), f"crop_size is {crop_size} and got dims={y}"
    cimg = img[..., z1:z2, y1:y2, x1:x2]
    return cimg

# %% ../../nbs/tfsm/10_voxt.ipynb 133
class RandPosCrop(BaseT):
    def __init__(self, crop_size: List[Tuple[int]], ignore_bbox=False, crop_strategy: str = "v1" , sample_size: int = 1, keep_volume: float = 0.5):
        """crop_size is [zyx]"""
        super().__init__()
        fc.store_attr()
        allowed_crop_strategy = ["v1", "v2"]
        if self.crop_strategy not in allowed_crop_strategy :
            raise ValueError(f"crop_strategy must be one of {allowed_crop_strategy}, got '{self.crop_strategy}' instead")

        self.crop_size_index = 0 

    __repr__ = fc.basic_repr(flds="crop_size")
    
    def apply(self, img: dict):
        crop_size = self.crop_size[self.crop_size_index]
        assert all([i in list(img.keys()) for i in ["boxes", "images"]])
        fimg, bbox = img["images"].copy(), img["boxes"].copy()
        img_shape = fimg.shape if len(fimg.shape) == 3 else fimg.shape[1:]
        bbox = clip_2_img(bbox, img_shape)        
        pimg, pbbox = pad3d_by_rsize(fimg, bbox, crop_size)

        if  (~self.ignore_bbox) & (pbbox.shape[0] != 0):
            if self.crop_strategy == "v1" : 
                cimg, cbbox, _ = random_crop(pimg, pbbox, crop_size, self.sample_size, self.keep_volume)
            if self.crop_strategy == "v2" : 
                cimg , cbbox, _ = random_crop_multi(pimg, pbbox, crop_size, self.sample_size, self.keep_volume)
        else:
            cimg = random_crop_img(pimg, crop_size)#no bounding boxes.
            cbbox = pbbox
        
        nimg = {"images": cimg, "boxes": cbbox}
        for i in img.keys(): 
            if i not in ["images", "boxes"]: nimg[i] = img[i]
        return nimg

# %% ../../nbs/tfsm/10_voxt.ipynb 145
class ApplyWindowsChannelWise(BaseT):
    from qct_utils.cv_ops.windowing import Window
    from typing import List
    def __init__(self, windows: List[Window], renorm: bool = True):
        super().__init__()
        fc.store_attr()
    __repr__ = fc.basic_repr(flds="windows,renorm")

    def apply(self, img: dict):
        assert "images" in img.keys(), "images key is not present"
        fimg = img["images"]
        nimg = {}
        nimg["images"] = self.apply_image(fimg)
        for i in img.keys(): 
            if i not in nimg.keys(): nimg[i] = img[i]
        return nimg 
    
    def apply_image(self, img):
        from qct_utils.cv_ops.windowing import stack_multiple_windows
        img = stack_multiple_windows(img , self.windows)
        if self.renorm:
            img = 2*img - 1 # renormalize the image from [-1, 1]
        return img
    
    def reverse_apply(self, img: dict): return img

# %% ../../nbs/tfsm/10_voxt.ipynb 146
class ToNumpy(BaseT):
    def __init__(self):
        super().__init__()

    def apply(self, img: dict):
        import torch
        assert "images" in img.keys(), "images key is not present"
        for i in img.keys(): 
            if isinstance(img[i] ,torch.Tensor) :
                img[i] = img[i].numpy()
        return img

    def reverse_apply(self, img: dict): return img
