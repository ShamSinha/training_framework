# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/05_safetensors.ipynb.

# %% auto 0
__all__ = [
    "get_scan_ids_inside_folder",
    "get_scan_ids_from_txt",
    "SafeTensorsDS",
    "MyCollateFn",
    "SafeTensorDL",
]

# %% ../nbs/05_safetensors.ipynb 2
import torch
import pandas as pd
import numpy as np
import fastcore.all as fc
import pytorch_lightning as pl

from pathlib import Path
from functools import partial
from typing import Union, List
from safetensors.numpy import load_file
from torchvision.transforms import Compose
from omegaconf import OmegaConf, ListConfig

from .utils import locate_cls


# %% ../nbs/05_safetensors.ipynb 23
def get_scan_ids_inside_folder(
    folder_path: Union[str, List[str]], ext: str = ".nii.gz"
):
    def _run(folder):
        return fc.L([i.name[:-7] for i in fc.L(Path(folder).glob(f"*{ext}"))])

    return (
        _run(folder_path)
        if isinstance(folder_path, str)
        else [j for i in folder_path for j in _run(i)]
    )


# %% ../nbs/05_safetensors.ipynb 25
def get_scan_ids_from_txt(file_path: str):
    files = [i.split()[0] for i in open(file_path, "r")]
    return files


# %% ../nbs/05_safetensors.ipynb 28
def get_scan_ids_inside_folder(
    folder_path: Union[str, List[str]], ext: str = ".nii.gz"
):
    def _run(folder):
        if ext == ".safetensors":
            return fc.L([i.name[:-12] for i in fc.L(Path(folder).glob(f"*{ext}"))])
        if ext == ".nii.gz":
            return fc.L([i.name[:-7] for i in fc.L(Path(folder).glob(f"*{ext}"))])
        else:
            raise NotImplementedError

    return (
        _run(folder_path)
        if isinstance(folder_path, str)
        else [j for i in folder_path for j in _run(i)]
    )


# %% ../nbs/05_safetensors.ipynb 31
class SafeTensorsDS(torch.utils.data.Dataset):
    def __init__(
        self,
        root: Union[str, List[str]],
        include: Union[str, List[str]] = None,
        individual_lung: bool = False,
    ):
        super().__init__()
        self.root = root
        # self.transforms = Compose(transforms) if transforms is not None else transforms
        if not individual_lung:
            self.imgs = (
                list(Path(root).glob("*.safetensors"))
                if isinstance(self.root, str)
                else [j for i in self.root for j in list(Path(i).glob("*.safetensors"))]
            )
        else:
            self.imgs = (
                list(Path(root).glob("*left.safetensors"))
                + list(Path(root).glob("*right.safetensors"))
                if isinstance(self.root, str)
                else [
                    j
                    for i in self.root
                    for j in list(Path(i).glob("*left.safetensors"))
                ]
                + [
                    j
                    for i in self.root
                    for j in list(Path(i).glob("*right.safetensors"))
                ]
            )

        if include is not None:
            if isinstance(include, list):

                if fc.Path(include[0]).suffix == ".csv":
                    series_ids = fc.L(
                        [j for i in include for j in pd.read_csv(i)["scans"].values]
                    )
                if fc.Path(include[0]).suffix == ".txt":
                    series_ids = fc.L(
                        [j for i in include for j in get_scan_ids_from_txt(i)]
                    )
            elif isinstance(include, str):
                series_ids = (
                    get_scan_ids_from_txt(include)
                    if ".txt" in include
                    else get_scan_ids_inside_folder(include)
                )

            if individual_lung:
                series_ids = [
                    s + suffix for s in series_ids for suffix in ["_left", "_right"]
                ]

            self.imgs = [i for i in self.imgs if i.stem in series_ids]

        print(f"total images: {len(self.imgs)}")
        if len(self.imgs) == 0:
            raise ValueError(
                f"there are no images with `.safetensors` as extensions in {self.root}"
            )

    def __getitem__(self, idx):
        fl = load_file(self.imgs[idx])
        fl["series_id"] = self.imgs[idx].stem
        # if self.transforms is not None: fl = self.transforms(fl)
        return fl

    def __len__(self):
        return len(self.imgs)


# %% ../nbs/05_safetensors.ipynb 38
from copy import deepcopy


class MyCollateFn:
    def __init__(self, transform, train):
        self.transform = transform
        self.train = train

    def __call__(self, batch):
        # Apply transformation to each item in the batch if needed

        transform = deepcopy(self.transform)

        if self.train:
            transform[4].crop_size_index = np.random.choice(len(transform[4].crop_size))
        transform = Compose(transform) if transform is not None else transform
        batch = [transform(item) for item in batch]

        series_id = []
        images = []
        for i in batch:
            if isinstance(i["images"], list):
                series_id.append([i["series_id"]] * len(i["images"]))
                images.extend(i["images"])
            else:
                series_id.append(i["series_id"])
                images.append(i["images"])

        images = [
            (
                torch.Tensor(i.astype(np.float32)).unsqueeze(0)
                if len(i.shape) == 3
                else torch.Tensor(i.astype(np.float32))
            )
            for i in images
        ]
        if self.train:
            images = torch.cat([i.unsqueeze(0) for i in images])

        boxes = []
        for i in batch:
            if isinstance(i["boxes"], list):
                boxes.extend(i["boxes"])
            else:
                boxes.append(i["boxes"])

        labels = []
        for i in range(len(boxes)):
            labels.append(np.zeros(boxes[i].shape[0]))

        boxes = [torch.Tensor(b.astype(np.float32)) for b in boxes]
        labels = [torch.Tensor(l.astype(np.float32)) for l in labels]

        return images, boxes, labels, series_id


# %% ../nbs/05_safetensors.ipynb 57
class SafeTensorDL(pl.LightningDataModule):
    def __init__(self, ts: dict, vs: dict = None):
        super().__init__()
        fc.store_attr()
        self.tds = self.load_ds(self.ts)
        self.vds = self.load_ds(self.vs)

        # train_transforms =  [i for i in self.ts.transform]
        # val_transforms =  [i for i in self.vs.transform]

        self.collate_safetensors_train = MyCollateFn(
            transform=self.ts.transform, train=True
        )
        self.collate_safetensors_val = MyCollateFn(
            transform=self.vs.transform, train=False
        )

        # if self.vs is not None:
        #    vs_include = self.vs["include"] if "include" in self.vs.keys() else None
        #    self.vds = SafeTensorsDS(vs.ds_paths, [locate_cls(i) for i in self.vs.transform], include=vs_include)

    def load_ds(self, ts):
        ts_dspaths = ts["ds_paths"] if "ds_paths" in ts.keys() else None
        if isinstance(ts_dspaths, ListConfig):
            ts_dspaths = OmegaConf.to_container(ts_dspaths, resolve=True)

        ts_include = ts["include"] if "include" in ts.keys() else None
        if isinstance(ts_include, ListConfig):
            ts_include = OmegaConf.to_container(ts_include, resolve=True)

        if isinstance(ts_dspaths, str):
            tds = SafeTensorsDS(
                ts_dspaths, include=ts_include, individual_lung=ts.individual_lung
            )
        elif isinstance(ts_dspaths, list):
            assert len(ts_dspaths) == len(
                ts_include
            ), "both ds_paths and ts include should be of same size and shape"
            tds = torch.utils.data.ConcatDataset(
                [
                    SafeTensorsDS(k, include=[v], individual_lung=w)
                    for k, v, w in zip(ts_dspaths, ts_include, ts.individual_lung)
                ]
            )
        else:
            raise NotImplementedError
        return tds

    def train_dl(self):
        return torch.utils.data.DataLoader(
            self.tds, collate_fn=self.collate_safetensors_train, **self.ts.dl
        )

    def val_dl(self):
        return torch.utils.data.DataLoader(
            self.vds, collate_fn=self.collate_safetensors_val, **self.vs.dl
        )
