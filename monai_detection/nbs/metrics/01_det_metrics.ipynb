{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c11609",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp metrics/det_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09415d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d3a0901",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "import torch \n",
    "import fastcore.all as fc\n",
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from typing import Tuple , List\n",
    "import torchmetrics\n",
    "\n",
    "from voxdet.bbox_func.bbox_iou import calculate_iou"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40105545",
   "metadata": {},
   "source": [
    "## Assign TP-FP-FN\n",
    "\n",
    "- When comparing a ground truth (gt) bounding box with a predicted bounding box, the following terms are used to evaluate the performance of the prediction:\n",
    "- `True Positive (tp):` a predicted bounding box that correctly identifies an object in the image and has a high overlap (usually measured by the Intersection over Union metric) with the corresponding ground truth bounding box.\n",
    "- `False Positive (fp):` a predicted bounding box that falsely identifies an object in the image and has a low overlap with any ground truth bounding box or no matching ground truth bounding box\n",
    "- `False Negative (fn):` a ground truth bounding box that is not matched to any predicted bounding box or has a low overlap with any predicted bounding box.\n",
    "- To assign tp, fp, fn to gt box and pred box, you can use a matching algorithm such as Hungarian algorithm to match each ground truth bounding box with the most similar predicted bounding box based on the overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "806b111b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def assign_tp_fp_fn_linear_assignment(pred_bbox: np.ndarray, gt_bbox: np.ndarray, iou_thr: float = 0.1):\n",
    "    \"\"\"\n",
    "    :param pred_bbox: predicted bounding boxes\n",
    "    :param gt_bbox: ground truth bounding boxes\n",
    "    :param iou_thr: iou threshold used to define true positive\n",
    "    :return: tp, fp, fn numpy ndarray of true positives, false positives, false negatives respectively\n",
    "\n",
    "    This function assigns true positives (tp), false positives (fp), and false negatives (fn) to the ground truth and predicted bounding boxes. It uses Hungarian algorithm to find the matching between gt_boxes and pred_boxes based on the iou (intersection over union) score. For each matching, if the iou score is greater than the threshold, it assigns 1 to the tp array of that index and 0 to the fp and fn array of that index. If there is no match or iou is less than threshold it assigns 1 to the fp and fn array of that index.\n",
    "    \"\"\"\n",
    "    # both gt_boxes and pred_boxes are empty, there should be no tp, fp, or fn\n",
    "    if len(gt_bbox) == 0 and len(pred_bbox) == 0:\n",
    "        return np.zeros(0), np.zeros(0), np.zeros(0), np.zeros(0)\n",
    "    # gt_boxes is empty, all predicted bounding boxes should be considered as fp\n",
    "    if len(gt_bbox) == 0:\n",
    "        return np.zeros(len(pred_bbox)), np.ones(len(pred_bbox)), np.zeros(0), np.zeros(0)\n",
    "    # pred_boxes is empty, all ground truth bounding boxes should be considered as fn\n",
    "    if len(pred_bbox) == 0:\n",
    "        return np.zeros(0), np.zeros(0), np.ones(len(gt_bbox)), np.zeros(0)\n",
    "\n",
    "    # calculate iou betwen pred_box and gt_box\n",
    "    overlaps = calculate_iou(pred_bbox, gt_bbox)\n",
    "    # use Hungarian algorithm to find the matching between gt_boxes and pred_boxes\n",
    "    row_ind, col_ind = linear_sum_assignment(-overlaps)\n",
    "\n",
    "    ## Assign TP, FP, FN\n",
    "    assignment = np.column_stack([row_ind, col_ind])\n",
    "    tp, fp, fn, pred_iou = np.zeros(len(pred_bbox)), np.ones(len(pred_bbox)), np.ones(len(gt_bbox)), np.zeros(len(pred_bbox))\n",
    "    for i, j in assignment:\n",
    "        iou = overlaps[i, j]\n",
    "        if iou >= iou_thr:\n",
    "            tp[i] = 1\n",
    "            fp[i] = 0\n",
    "            fn[j] = 0\n",
    "            pred_iou[i] = iou\n",
    "    \n",
    "    tp_iou = pred_iou[tp.astype(np.int8) == 1]\n",
    "    return tp, fp, fn, tp_iou\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9025f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 6])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.hstack([torch.randint(20, size=(1000, 1)) for _ in range(3)])\n",
    "y = torch.Tensor([[40, 40, 40] for i in range(1000)])\n",
    "xy = torch.hstack([x, y])\n",
    "xy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "447e37af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42.6 ms, sys: 6.65 ms, total: 49.2 ms\n",
      "Wall time: 57.1 ms\n"
     ]
    }
   ],
   "source": [
    "%time _ = assign_tp_fp_fn_linear_assignment(xy.numpy(), xy.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693e5156",
   "metadata": {},
   "source": [
    "### Test 1\n",
    "> Gt boxes are zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92bd08ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_bbox = np.array([[10, 10, 20, 20], [50, 50, 60, 60], [30, 30, 40, 40]])\n",
    "gt_bbox = np.array([])\n",
    "TP, FP, FN, TP_IOU = assign_tp_fp_fn_linear_assignment(pred_bbox, gt_bbox)\n",
    "fc.all_equal(FN, np.array([]))\n",
    "fc.all_equal(FP, np.array([1, 1, 1]))\n",
    "fc.all_equal(TP, np.array([0, 0, 0]))\n",
    "fc.all_equal(TP_IOU, np.array([]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3eb2e7",
   "metadata": {},
   "source": [
    "### Test 2\n",
    "> both gt and pred bboxes are zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71a3f719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_bbox, gt_bbox = np.array([]), np.array([])\n",
    "TP, FP, FN, TP_IOU = assign_tp_fp_fn_linear_assignment(pred_bbox, gt_bbox)\n",
    "fc.all_equal(FN, np.array([]))\n",
    "fc.all_equal(FP, np.array([]))\n",
    "fc.all_equal(TP, np.array([]))\n",
    "fc.all_equal(TP_IOU, np.array([]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c45659",
   "metadata": {},
   "source": [
    "### Test 3\n",
    "> no gt boxes but pred boxes are present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9336a151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_bbox = np.array([])\n",
    "gt_bbox = np.array([[10, 10, 20, 20], [50, 50, 60, 60], [30, 30, 40, 40]])\n",
    "TP, FP, FN, TP_IOU = assign_tp_fp_fn_linear_assignment(pred_bbox, gt_bbox)\n",
    "fc.all_equal(TP, np.array([]))\n",
    "fc.all_equal(FP, np.array([]))\n",
    "fc.all_equal(FN, np.array([1, 1, 1]))\n",
    "fc.all_equal(TP_IOU, np.array([]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9015b6",
   "metadata": {},
   "source": [
    "### Test 4\n",
    "> Gt boxes and Pred boxes with one overlap exactly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7d76c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_boxes = np.array([(10, 20, 30, 40), (50, 60, 70, 80), (90, 100, 110, 120)])\n",
    "pred_boxes = np.array([(15, 25, 35, 45), (55, 65, 75, 85), (95, 105, 115, 125)])\n",
    "TP, FP, FN, TP_IOU = assign_tp_fp_fn_linear_assignment(pred_boxes, gt_boxes)\n",
    "fc.test_eq(len(FN), len(gt_boxes))\n",
    "assert len(FP) == len(TP) == len(pred_boxes)\n",
    "fc.all_equal(TP, np.array([1, 1, 1]))\n",
    "fc.all_equal(FP, np.array([0, 0, 0]))\n",
    "fc.all_equal(FN, np.array([0, 0, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7a5b7ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.39130435, 0.39130435, 0.39130435])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP_IOU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "867a5401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.391304347826087"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AVG_TP_IOU = 0 if not TP_IOU.size else np.mean(TP_IOU, axis=0)\n",
    "AVG_TP_IOU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172ad41b",
   "metadata": {},
   "source": [
    "### Test 5\n",
    "> One Gt box - multiple Preds with same overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "513d04e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_boxes = np.array([(10, 20, 30, 40), (50, 60, 70, 80), (90, 100, 110, 120)])\n",
    "pred_boxes = np.array([(15, 25, 35, 45), (55, 65, 75, 85), (95, 105, 115, 125), (95, 105, 115, 130)])\n",
    "TP, FP, FN, TP_IOU = assign_tp_fp_fn_linear_assignment(pred_boxes, gt_boxes)\n",
    "assert (len(FN) == len(gt_boxes)) & \\\n",
    "       (len(FP) == len(TP) == len(pred_boxes)), \\\n",
    "       \"lengths of TP, FP, FN doesnt match with gt_boxes and pred_boxes\"\n",
    "\n",
    "fc.all_equal(TP, np.array([1, 1, 1, 0]))\n",
    "fc.all_equal(FP, np.array([0, 0, 0, 1]))\n",
    "fc.all_equal(FN, np.array([0, 0, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468ae5de",
   "metadata": {},
   "source": [
    "### Test-6\n",
    ">  One Gt box - multiple Preds with different overlap scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a592012f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_boxes = np.array([(10, 20, 30, 40), (50, 60, 70, 80), (90, 100, 110, 120)])\n",
    "pred_boxes = np.array([(15, 25, 35, 45), (55, 65, 75, 85), (95, 105, 115, 125), (90, 100, 110, 120)])\n",
    "TP, FP, FN, TP_IOU = assign_tp_fp_fn_linear_assignment(pred_boxes, gt_boxes)\n",
    "assert (len(FN) == len(gt_boxes)) & (\n",
    "        len(FP) == len(TP) == len(pred_boxes)\n",
    "    ), \"lengths of TP, FP, FN doesnt match with gt_boxes and pred_boxes\"\n",
    "fc.all_equal(TP, np.array([1, 1, 0, 1]))\n",
    "fc.all_equal(FP, np.array([0, 0, 1, 0]))\n",
    "fc.all_equal(FN, np.array([0, 0, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2de1a2d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.39130435, 0.39130435, 1.        ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP_IOU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "201a2f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5942028985507246"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AVG_TP_IOU = 0 if not TP_IOU.size else np.mean(TP_IOU, axis=0)\n",
    "AVG_TP_IOU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea28aeb1",
   "metadata": {},
   "source": [
    "### Test-7\n",
    "> No overlaps between GT and Preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b9ddc9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_boxes = np.array([(10, 20, 30, 40), (50, 60, 70, 80), (90, 100, 110, 120)])\n",
    "pred_boxes = np.array([(1150, 1125, 1135, 1145), \\\n",
    "                       (1155, 1165, 1175, 1185), \\\n",
    "                       (1115, 1105, 1125, 1125), \\\n",
    "                       (1195, 1105, 2115, 2130)])\n",
    "TP, FP, FN, TP_IOU = assign_tp_fp_fn_linear_assignment(pred_boxes, gt_boxes)\n",
    "assert (len(FN) == len(gt_boxes)) & (\n",
    "        len(FP) == len(TP) == len(pred_boxes)\n",
    "    ), \"lengths of TP, FP, FN doesnt match with gt_boxes and pred_boxes\"\n",
    "\n",
    "fc.all_equal(TP, np.array([1, 1, 1, 1]))\n",
    "fc.all_equal(FP, np.array([0, 0, 0, 0]))\n",
    "fc.all_equal(FN, np.array([1, 1, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "966e6f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP_IOU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf8553e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AVG_TP_IOU = 0 if not TP_IOU.size else np.mean(TP_IOU, axis=0)\n",
    "AVG_TP_IOU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8d62fa",
   "metadata": {},
   "source": [
    "### Test-8\n",
    "> Gt boxes and Pred boxes with one overlap exactly but iou less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aaf18513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_boxes = np.array([(10, 20, 30, 40), (50, 60, 70, 80), (90, 100, 110, 120)])\n",
    "pred_boxes = np.array([(15, 25, 35, 45), (55, 65, 75, 85), (95, 105, 115, 125)])\n",
    "TP, FP, FN, _ = assign_tp_fp_fn_linear_assignment(pred_boxes, gt_boxes, iou_thr=0.5)\n",
    "assert (len(FN) == len(gt_boxes)) & (\n",
    "    len(FP) == len(TP) == len(pred_boxes)\n",
    "), \"lengths of TP, FP, FN doesnt match with gt_boxes and pred_boxes\"\n",
    "\n",
    "fc.all_equal(TP, np.array([0, 0, 0]))\n",
    "fc.all_equal(FP, np.array([1, 1, 1]))\n",
    "fc.all_equal(FN, np.array([1, 1, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c392a96e",
   "metadata": {},
   "source": [
    "## Calculate Metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "078845dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class DetMetrics:\n",
    "    # inspired from https://github.com/rafaelpadilla/Object-Detection-Metrics#average-precision\n",
    "    def __init__(self, iou_thr: float = 0.1, conf_thr: float = 0.1, froc_thresholds: Tuple = (0.25, 0.5, 1, 2, 4, 8)):\n",
    "        fc.store_attr()\n",
    "        self.reset()\n",
    "        self._metric_list = [\"AP_interp\", \"FROC_interp\", \"FROC\", \"AP\", \"recall\", \"tp\", \"fp\", \"fn\", \"precision\", \"FROC_thresholds\", \"avg_tp_iou\"]\n",
    "\n",
    "    def update(self, pred_bbox: np.ndarray, pred_scores: np.ndarray, gt_bbox: np.ndarray):\n",
    "        keep = pred_scores >= self.conf_thr\n",
    "        pred_bbox = pred_bbox[keep]\n",
    "        pred_scores = pred_scores[keep]\n",
    "        tp, fp, fn, tp_iou = assign_tp_fp_fn_linear_assignment(pred_bbox, gt_bbox, iou_thr=self.iou_thr)\n",
    "        self.num_images += 1\n",
    "        self.tp = np.hstack([self.tp, tp])\n",
    "        self.fp = np.hstack([self.fp, fp])\n",
    "        self.fn = np.hstack([self.fn, fn])\n",
    "        self.tp_iou = np.hstack([self.tp_iou, tp_iou])\n",
    "        self.conf = np.hstack([self.conf, pred_scores])\n",
    "\n",
    "    def reset(self):\n",
    "        self.tp, self.fp, self.fn, self.conf, self.tp_iou = np.zeros(0), np.zeros(0), np.zeros(0), np.zeros(0), np.zeros(0)\n",
    "        self.num_images = 0\n",
    "\n",
    "    def compute(self):\n",
    "        metrics = {}\n",
    "        metrics[\"conf\"] = self.conf_thr\n",
    "        metrics[\"iou\"] = self.iou_thr\n",
    "        if self.tp.shape[0] == 0:\n",
    "            for i in self._metric_list: metrics[i] = 0\n",
    "            metrics[\"fn\"] = np.sum(self.fn)\n",
    "            return metrics \n",
    "        \n",
    "        tp, fp, _ = zip(*sorted(zip(self.tp, self.fp, self.conf), key=lambda x: x[2], reverse=True))\n",
    "        precision = np.cumsum(tp) / (np.cumsum(tp) + np.cumsum(fp)+1e-16)\n",
    "        sensitivity = np.cumsum(tp) / (sum(tp) + sum(self.fn))\n",
    "        fpr = np.cumsum(fp) / self.num_images\n",
    "\n",
    "        ## Update metrics\n",
    "        metrics[\"FROC_thresholds\"] = list(self.froc_thresholds)\n",
    "        metrics[\"AP_interp\"] = np.interp(np.linspace(0, 1, 11), sensitivity, precision).tolist()\n",
    "        metrics[\"FROC_interp\"] = np.interp(self.froc_thresholds, fpr, sensitivity).tolist()\n",
    "        metrics[\"FROC\"] = np.mean(metrics[\"FROC_interp\"])\n",
    "        metrics[\"AP\"] = np.mean(metrics[\"AP_interp\"])\n",
    "        metrics[\"recall\"] = sensitivity.max()\n",
    "        metrics[\"tp\"] = np.sum(self.tp)\n",
    "        metrics[\"fp\"] = np.sum(self.fp)\n",
    "        metrics[\"avg_tp_iou\"] = 0 if not self.tp_iou.size else np.mean(self.tp_iou, axis=0)\n",
    "        metrics[\"precision\"] = metrics[\"tp\"]/(metrics[\"tp\"] + metrics[\"fp\"])\n",
    "        metrics[\"fn\"] = np.sum(self.fn)\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e95e258c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DetMetrics(torchmetrics.Metric):\n",
    "    def __init__(self, \n",
    "                 iou_thr: float = 0.1, \n",
    "                 conf_thr: float = 0.1, \n",
    "                 froc_thresholds: Tuple[float, ...] = (0.25, 0.5, 1, 2, 4, 8), \n",
    "                 dist_sync_on_step=False):\n",
    "        super().__init__(dist_sync_on_step=dist_sync_on_step)\n",
    "        self.iou_thr = iou_thr\n",
    "        self.conf_thr = conf_thr\n",
    "        self.froc_thresholds = froc_thresholds\n",
    "        self.to_np = lambda x: x.detach().cpu().numpy()\n",
    "\n",
    "        self.add_state(\"tps\", default=[], dist_reduce_fx=None)\n",
    "        self.add_state(\"fps\", default=[], dist_reduce_fx=None)\n",
    "        self.add_state(\"fns\", default=[], dist_reduce_fx=None)\n",
    "        self.add_state(\"confs\", default=[], dist_reduce_fx=None)\n",
    "        self.add_state(\"tp_ious\", default=[], dist_reduce_fx=None)\n",
    "        self.add_state(\"num_images\", default=torch.tensor(0.), dist_reduce_fx=None)\n",
    "\n",
    "    def update(self, pred_bbox, pred_scores, gt_bbox):\n",
    "        keep = pred_scores >= self.conf_thr\n",
    "        pred_bbox = pred_bbox[keep]\n",
    "        pred_scores = pred_scores[keep]\n",
    "\n",
    "        tp, fp, fn, tp_iou = assign_tp_fp_fn_linear_assignment(self.to_np(pred_bbox), self.to_np(gt_bbox), self.iou_thr)\n",
    "\n",
    "        self.tps.append(torch.tensor(tp, dtype=torch.float32).to(self.device))\n",
    "        self.fps.append(torch.tensor(fp, dtype=torch.float32).to(self.device))\n",
    "        self.fns.append(torch.tensor(fn, dtype=torch.float32).to(self.device))\n",
    "        self.tp_ious.append(torch.tensor(tp_iou, dtype=torch.float32).to(self.device))\n",
    "        self.confs.append(torch.tensor(pred_scores, dtype=torch.float32).to(self.device))\n",
    "        self.num_images += 1\n",
    "\n",
    "    def compute(self):\n",
    "        # Ensure there is at least one TP to avoid division by zero\n",
    "\n",
    "        self.tps = torch.cat(self.tps)\n",
    "        self.fps = torch.cat(self.fps)\n",
    "        self.fns = torch.cat(self.fns)\n",
    "        self.tp_ious = torch.cat(self.tp_ious)\n",
    "        self.confs = torch.cat(self.confs)\n",
    "        self.num_images = torch.sum(self.num_images)\n",
    "      \n",
    "        metrics = {}\n",
    "        metrics[\"conf\"] = self.conf_thr\n",
    "        metrics[\"iou\"] = self.iou_thr\n",
    "        \n",
    "        if self.tps == []:\n",
    "            metrics[\"fn\"] = self.fns.sum().item()\n",
    "            # Initialize other metrics as well, if needed\n",
    "            return metrics \n",
    "\n",
    "        # Sorting based on confidences\n",
    "        sorted_indices = torch.argsort(self.confs, descending=True)\n",
    "        tp_sorted = self.tps[sorted_indices].cpu().numpy()  # Ensure conversion to numpy\n",
    "        fp_sorted = self.fps[sorted_indices].cpu().numpy()  # Ensure conversion to numpy\n",
    "\n",
    "        # Cumulative sums for TP and FP to calculate precision and recall\n",
    "        tp_cumsum = np.cumsum(tp_sorted)\n",
    "        fp_cumsum = np.cumsum(fp_sorted)\n",
    "\n",
    "        num_positives = tp_cumsum[-1] + self.fns.sum().item()\n",
    "\n",
    "        precision = tp_cumsum / (tp_cumsum + fp_cumsum)\n",
    "        recall = tp_cumsum / num_positives\n",
    "        fpr = fp_cumsum / self.num_images.item()\n",
    "\n",
    "        # Interpolation for AP_interp and FROC_interp\n",
    "        AP_interp = np.interp(np.linspace(0, 1, 11), recall, precision, right=0)\n",
    "        FROC_interp = np.interp(self.froc_thresholds, fpr, recall, right=0)\n",
    "\n",
    "        # Update metrics directly with numpy values\n",
    "        metrics[\"FROC_thresholds\"] = self.froc_thresholds\n",
    "        metrics[\"AP_interp\"] = AP_interp.tolist()\n",
    "        metrics[\"FROC_interp\"] = FROC_interp.tolist()\n",
    "        metrics[\"FROC\"] = FROC_interp.mean()\n",
    "        metrics[\"AP\"] = AP_interp.mean()\n",
    "        metrics[\"recall\"] = recall.max()\n",
    "        metrics[\"tp\"] = tp_cumsum[-1]\n",
    "        metrics[\"fp\"] = fp_cumsum[-1]\n",
    "        metrics[\"avg_tp_iou\"] = np.mean(self.tp_ious.cpu().numpy()) if self.tp_ious.numel() > 0 else 0  # Ensure conversion to numpy and handling as numpy array\n",
    "        metrics[\"precision\"] = precision[-1]\n",
    "        metrics[\"fn\"] = self.fns.sum().item()\n",
    "\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1607137",
   "metadata": {},
   "source": [
    "### Test-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ecc58d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/shubham.kumar/miniconda3/envs/qct_deep_clone/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: The ``compute`` method of metric DetMetrics was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iou_thr = 0.1\n",
    "meters = DetMetrics(iou_thr=iou_thr)\n",
    "meters.tps = torch.Tensor([1, 1, 1, 1, 1])\n",
    "meters.fps = torch.Tensor([0, 0, 0, 0, 0])\n",
    "meters.fns = torch.Tensor([0, 0, 0, 0, 0])\n",
    "meters.confs = torch.Tensor([1, 1, 1, 1, 1])\n",
    "meters.tp_ious = torch.Tensor([1, 1, 1, 1, 1])\n",
    "meters.num_images = torch.tensor(3)\n",
    "meters.eval_thresholds = [1 / 8, 1 / 4, 1, 2, 4, 8]\n",
    "\n",
    "expected_AP_interp = np.ones(11).tolist()\n",
    "expected_FROC_interp = np.ones(6).tolist()\n",
    "metrics = meters.compute()\n",
    "\n",
    "fc.eq(metrics[\"AP_interp\"], expected_AP_interp)\n",
    "fc.eq(metrics[\"FROC_interp\"], expected_FROC_interp)\n",
    "fc.eq(metrics[\"recall\"], 1)\n",
    "fc.eq(metrics[\"precision\"], 1)\n",
    "fc.eq(metrics[\"avg_tp_iou\"], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3494f48d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iou_thr = 0.3\n",
    "meters = DetMetrics(iou_thr=iou_thr)\n",
    "meters.tps = []\n",
    "meters.fps = torch.Tensor([1, 1, 1, 1, 1])\n",
    "meters.fns = torch.Tensor([1, 1, 1, 1, 1])\n",
    "meters.confs = torch.Tensor([0, 0, 0, 0, 0])\n",
    "meters.tp_ious = []\n",
    "meters.num_images = torch.tensor(3)\n",
    "meters.eval_thresholds = [1 / 8, 1 / 4, 1, 2, 4, 8]\n",
    "\n",
    "expected_AP_interp = np.ones(11).tolist()\n",
    "expected_FROC_interp = np.ones(6).tolist()\n",
    "metrics = meters.compute()\n",
    "\n",
    "fc.eq(metrics[\"fn\"], 5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72beb31d",
   "metadata": {},
   "source": [
    "### Test-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9530e51c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iou_thr = 0.1\n",
    "meters = DetMetrics(iou_thr=iou_thr)\n",
    "meters.tps = torch.Tensor([0, 1, 0, 1, 0])\n",
    "meters.fps = torch.Tensor([1, 0, 1, 0, 1])\n",
    "meters.fns = torch.Tensor([0, 1, 1, 0])\n",
    "meters.confs = torch.Tensor([0.5, 0.5, 0.5, 0.5, 0.5])\n",
    "\n",
    "tp_count = int(meters.tps.sum().item())\n",
    "\n",
    "torch.manual_seed(24)\n",
    "meters.tp_ious = torch.rand(tp_count) * (1 - iou_thr) + iou_thr\n",
    "\n",
    "meters.num_images = torch.tensor(3)\n",
    "meters.eval_thresholds = [1 / 8, 1 / 4, 1, 2, 4, 8]\n",
    "metrics = meters.compute()\n",
    "\n",
    "fc.test_close(metrics[\"AP_interp\"], [0.0, 0.2, 0.4, 0.367, 0.434, 0.4, 0 , 0 , 0 , 0 ,0], eps=1e-2)\n",
    "fc.test_close(metrics[\"FROC_interp\"], [0.0, 0.25, 0.5, 0.0, 0.0, 0.0], eps=1e-2)\n",
    "fc.eq(metrics[\"precision\"], 0.4)\n",
    "fc.eq(metrics[\"recall\"], 0.5)\n",
    "fc.eq(metrics[\"fn\"], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ed9c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7b8dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
