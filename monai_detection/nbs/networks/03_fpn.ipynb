{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29dfeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp networks/fpn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe313369",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import fastcore.all as fc\n",
    "from typing import Dict, List\n",
    "from monai.networks.blocks.feature_pyramid_network import FeaturePyramidNetwork, LastLevelMaxPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09c3720e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from voxdet.networks.res_se_net import resnet10, conv3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d1dacda",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = resnet10(1, (7, 7, 7), (1, 2, 2), base_pool=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3f2afda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layer1': '0', 'layer2': '1', 'layer3': '2', 'layer4': '3'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returned_layers = [1, 2, 3, 4]\n",
    "return_layers = {f\"layer{k}\": str(v) for v, k in enumerate(returned_layers)}\n",
    "return_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ecef653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[64, 128, 256, 512]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_channels_list = [(512//8) * 2 ** (i - 1) for i in returned_layers]\n",
    "in_channels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78ed5434",
   "metadata": {},
   "outputs": [],
   "source": [
    "body = torchvision.models._utils.IntermediateLayerGetter(backbone, return_layers=return_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8230c57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IntermediateLayerGetter(\n",
       "  (base): Sequential(\n",
       "    (0): Conv3d(1, 64, kernel_size=(7, 7, 7), stride=(1, 2, 2), padding=(3, 3, 3), bias=False)\n",
       "    (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): GeneralRelu: leak:0.1-sub:0.4-maxv:None\n",
       "  )\n",
       "  (layer1): ResStage(\n",
       "    (block0): ResBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): GeneralRelu: leak:0.1-sub:0.4-maxv:None\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (act): GeneralRelu: leak:0.1-sub:0.4-maxv:None\n",
       "    )\n",
       "  )\n",
       "  (layer2): ResStage(\n",
       "    (block0): ResBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): GeneralRelu: leak:0.1-sub:0.4-maxv:None\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
       "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (act): GeneralRelu: leak:0.1-sub:0.4-maxv:None\n",
       "    )\n",
       "  )\n",
       "  (layer3): ResStage(\n",
       "    (block0): ResBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): GeneralRelu: leak:0.1-sub:0.4-maxv:None\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
       "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (act): GeneralRelu: leak:0.1-sub:0.4-maxv:None\n",
       "    )\n",
       "  )\n",
       "  (layer4): ResStage(\n",
       "    (block0): ResBlock(\n",
       "      (convs): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): GeneralRelu: leak:0.1-sub:0.4-maxv:None\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
       "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (act): GeneralRelu: leak:0.1-sub:0.4-maxv:None\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a65ffb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 96, 192, 192])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = torch.ones((1, 1, 96, 192, 192))\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41eb6a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53.3 s, sys: 29 s, total: 1min 22s\n",
      "Wall time: 1.54 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('0', torch.Size([1, 64, 96, 96, 96])),\n",
       " ('1', torch.Size([1, 128, 48, 48, 48])),\n",
       " ('2', torch.Size([1, 256, 24, 24, 24])),\n",
       " ('3', torch.Size([1, 512, 12, 12, 12]))]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "outs = body(img)\n",
    "[(k, v.shape) for k, v in outs.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef44c29c",
   "metadata": {},
   "source": [
    "### FeaturePyramidNetwork\n",
    "\n",
    "- One pyramid level for each stage - C2, C3, C4, C5. In this case we are taking C1 and C2 . this has stride of (1, 2, 2) and (2, 4, 4). \n",
    "- Take C2 and upsample by a factor of 2 (using nearest neighbor upsampling for simplicity)\n",
    "- take C1 -  1x1 conv to reduce the channel dimension\n",
    "- Add 1 and 2 element wise \n",
    "- 3x3 on each merged map to generate the final feature map \n",
    "- we get P2 \n",
    "\n",
    "similarly we do for other layers too \n",
    "\n",
    "- set d=256 \n",
    "- All levels of the pyramid use shared classifiers/regressors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f038eaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "class BackbonewithFPN3D(nn.Module):\n",
    "    def __init__(self, backbone, return_layers: Dict[str, str], in_channels_list: List[int],\\\n",
    "                 out_channels: int, extra_blocks: bool=False):\n",
    "        super().__init__()\n",
    "        fc.store_attr(names=[\"return_layers\", \"in_channels_list\", \"out_channels\"])\n",
    "        self.body = torchvision.models._utils.IntermediateLayerGetter(backbone, return_layers=return_layers)\n",
    "        self.fpn = FeaturePyramidNetwork( \n",
    "            spatial_dims=3, \n",
    "            in_channels_list=in_channels_list,\n",
    "            out_channels=out_channels,\n",
    "            extra_blocks=LastLevelMaxPool(3) if extra_blocks else None,\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.body(x)\n",
    "        y = self.fpn(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba1520fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def resnet_fpn3d_feature_extractor(backbone, out_channels=256, returned_layers=[1, 2, 3], extra_blocks:bool=False):\n",
    "    in_channels_stage2 = backbone.ip[-1] // 8\n",
    "    in_channels_list = [in_channels_stage2 * 2 ** (i - 1) for i in returned_layers]\n",
    "    return_layers = {f\"layer{k}\": str(v) for v, k in enumerate(returned_layers)}\n",
    "    return BackbonewithFPN3D(backbone, return_layers, in_channels_list, out_channels, extra_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1454c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = resnet_fpn3d_feature_extractor(backbone, extra_blocks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3e3a890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 46s, sys: 1min 34s, total: 3min 20s\n",
      "Wall time: 4.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "outs = network(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e237078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0', torch.Size([1, 256, 96, 96, 96])),\n",
       " ('1', torch.Size([1, 256, 48, 48, 48])),\n",
       " ('2', torch.Size([1, 256, 24, 24, 24])),\n",
       " ('pool', torch.Size([1, 256, 12, 12, 12]))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(k, v.shape) for k, v in outs.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8d1bb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_params(layer):\n",
    "    n=0\n",
    "    for name, params in layer.named_parameters(): n+=params.numel()\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "950e953a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9029568"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_params(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf1b618",
   "metadata": {},
   "source": [
    "## Comparing it with monai implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c231046",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cfg = dict(\n",
    "  spatial_dims = 3,\n",
    "  pretrained_backbone = False,\n",
    "  trainable_backbone_layers = None, \n",
    "  returned_layers = [1, 2, 3],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7e6df00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.apps.detection.networks.retinanet_network import resnet_fpn_feature_extractor as rffe\n",
    "backbone.in_planes = 512\n",
    "feature_extractor = rffe(backbone=backbone, **model_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80f7e772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9029568"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_params(feature_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "89d14af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 7s, sys: 1min 17s, total: 3min 24s\n",
      "Wall time: 4.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "outs = feature_extractor(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "065356bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0', torch.Size([1, 256, 96, 96, 96])),\n",
       " ('1', torch.Size([1, 256, 48, 48, 48])),\n",
       " ('2', torch.Size([1, 256, 24, 24, 24])),\n",
       " ('pool', torch.Size([1, 256, 12, 12, 12]))]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(k, v.shape) for k, v in outs.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e9f235",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db55b655",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
