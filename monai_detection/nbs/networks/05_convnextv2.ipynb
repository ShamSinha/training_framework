{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18be6b05",
   "metadata": {},
   "source": [
    "we will be implementing `convNextv2` here. \n",
    "\n",
    "This is already implemented in [medct]. we will use this as backbone here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5cf3327",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp networks/convnextv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dad7029",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import fastcore.all as fc\n",
    "\n",
    "from collections import OrderedDict\n",
    "from medct.convnextv2 import ConvNextV2Model3d, ConvNextV2Config3d\n",
    "from monai.networks.blocks.feature_pyramid_network import FeaturePyramidNetwork, LastLevelMaxPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c526c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = ConvNextV2Config3d(num_channels=1, image_size=(96, 192, 192), num_stages=3, hidden_sizes=[80, 160, 320], depths=[3, 6, 3])\n",
    "backbone = ConvNextV2Model3d(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c670dcf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5134400"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for name, params in backbone.state_dict().items():\n",
    "    count+=params.numel()\n",
    "count "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4667aff",
   "metadata": {},
   "source": [
    "Atto: depths=[2, 2, 6, 2], dims=[40, 80, 160, 320]  \n",
    "fempto: depths=[2, 2, 6, 2], dims=[48, 96, 192, 384]  \n",
    "pico: depths=[2, 2, 6, 2], dims=[64, 128, 256, 512]  \n",
    "nano: depths=[2, 2, 8, 2], dims=[80, 160, 320, 640]  \n",
    "tiny: depths=[3, 3, 9, 3], dims=[96, 192, 384, 768]  \n",
    "base: depths=[3, 3, 27, 3], dims=[128, 256, 512, 1024]  \n",
    "large: depths=[3, 3, 27, 3], dims=[192, 384, 768, 1536]  \n",
    "huge: depths=[3, 3, 27, 3], dims=[352, 704, 1408, 2816]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c44b9963",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sizes = dict(\n",
    "atto = dict(depths=[2, 2, 6, 2], dims=[40, 80, 160, 320]), \n",
    "fempto = dict(depths=[2, 2, 6, 2], dims=[48, 96, 192, 384]),  \n",
    "pico= dict(depths=[2, 2, 6, 2], dims=[64, 128, 256, 512]), \n",
    "nano= dict(depths=[2, 2, 8, 2], dims=[80, 160, 320, 640]), \n",
    "tiny= dict(depths=[3, 3, 9, 3], dims=[96, 192, 384, 768]), \n",
    "base= dict(depths=[3, 3, 27, 3], dims=[128, 256, 512, 1024]), \n",
    "large= dict(depths=[3, 3, 27, 3], dims=[192, 384, 768, 1536]), \n",
    "huge= dict(depths=[3, 3, 27, 3], dims=[352, 704, 1408, 2816]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b5b3563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atto {'depths': [2, 2, 6, 2], 'dims': [40, 80, 160, 320]} 4197800\n",
      "fempto {'depths': [2, 2, 6, 2], 'dims': [48, 96, 192, 384]} 5885232\n",
      "pico {'depths': [2, 2, 6, 2], 'dims': [64, 128, 256, 512]} 10107968\n",
      "nano {'depths': [2, 2, 8, 2], 'dims': [80, 160, 320, 640]} 17329360\n",
      "tiny {'depths': [3, 3, 9, 3], 'dims': [96, 192, 384, 768]} 31363776\n",
      "base {'depths': [3, 3, 27, 3], 'dims': [128, 256, 512, 1024]} 95753472\n",
      "large {'depths': [3, 3, 27, 3], 'dims': [192, 384, 768, 1536]} 210575232\n",
      "huge {'depths': [3, 3, 27, 3], 'dims': [352, 704, 1408, 2816]} 692885952\n"
     ]
    }
   ],
   "source": [
    "for name, params in model_sizes.items():\n",
    "    cfg = ConvNextV2Config3d(num_channels=1, image_size=(96, 192, 192), num_stages=4, hidden_sizes=params[\"dims\"], depths=params[\"depths\"])\n",
    "    backbone = ConvNextV2Model3d(cfg)\n",
    "    count = 0\n",
    "    for _, paramst in backbone.state_dict().items():\n",
    "        count+=paramst.numel()\n",
    "    print(name, params, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abc4f61",
   "metadata": {},
   "source": [
    "> what if we want to use only depth of 2 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa7649f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sizes = dict(\n",
    "atto = dict(depths=[3, 3], dims=[40, 80]), \n",
    "fempto = dict(depths=[3, 3], dims=[48, 96]),  \n",
    "pico= dict(depths=[3, 3], dims=[64, 128]), \n",
    "nano= dict(depths=[3, 6], dims=[80, 160]), \n",
    "tiny= dict(depths=[3, 6], dims=[96, 192]), \n",
    "base= dict(depths=[3, 6], dims=[128, 256]), \n",
    "large= dict(depths=[3, 6], dims=[192, 384]), \n",
    "huge= dict(depths=[3, 6], dims=[352, 704]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9106b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atto {'depths': [3, 3], 'dims': [40, 80]} 349840\n",
      "fempto {'depths': [3, 3], 'dims': [48, 96]} 472032\n",
      "pico {'depths': [3, 3], 'dims': [64, 128]} 768640\n",
      "nano {'depths': [3, 6], 'dims': [80, 160]} 1921600\n",
      "tiny {'depths': [3, 6], 'dims': [96, 192]} 2662272\n",
      "base {'depths': [3, 6], 'dims': [128, 256]} 4499968\n",
      "large {'depths': [3, 6], 'dims': [192, 384]} 9600768\n",
      "huge {'depths': [3, 6], 'dims': [352, 704]} 30667648\n"
     ]
    }
   ],
   "source": [
    "for name, params in model_sizes.items():\n",
    "    cfg = ConvNextV2Config3d(num_channels=1, image_size=(96, 192, 192), num_stages=2, hidden_sizes=params[\"dims\"], depths=params[\"depths\"])\n",
    "    backbone = ConvNextV2Model3d(cfg)\n",
    "    count = 0\n",
    "    for _, paramst in backbone.state_dict().items():\n",
    "        count+=paramst.numel()\n",
    "    print(name, params, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c4036d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = backbone(torch.randn((1, 1, 96, 192, 192)), output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76b6b54c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 704, 12, 24, 24])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c910ee36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 352, 24, 48, 48]),\n",
       " torch.Size([1, 352, 24, 48, 48]),\n",
       " torch.Size([1, 704, 12, 24, 24])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i.shape for i in out.hidden_states]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3a17f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "class ConvNextV2BackbonewithFPN3D(nn.Module):\n",
    "    def __init__(self, backbone_cfg, returned_layers=[1, 2], out_channels=256, extra_blocks=False):\n",
    "        super().__init__()\n",
    "        fc.store_attr(names=[\"backbone_cfg\", \"returned_layers\", \"out_channels\", \"extra_blocks\"])\n",
    "        from omegaconf import DictConfig, OmegaConf #during inference self.backbone_cfg is DictConfig which is not supported by transformers.\n",
    "        if isinstance(self.backbone_cfg, DictConfig):\n",
    "            self.backbone_cfg = OmegaConf.to_object(self.backbone_cfg)\n",
    "        self.cfg = ConvNextV2Config3d(**self.backbone_cfg)\n",
    "        self.body = ConvNextV2Model3d(self.cfg)\n",
    "        self.fpn = FeaturePyramidNetwork( \n",
    "            spatial_dims=3, \n",
    "            in_channels_list=self.cfg.hidden_sizes,\n",
    "            out_channels=out_channels,\n",
    "            extra_blocks=LastLevelMaxPool(3) if extra_blocks else None,\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.body(x, output_hidden_states=True).hidden_states\n",
    "        out = OrderedDict({f\"layer{k}\": v for k, v in enumerate(out) if k in self.returned_layers})\n",
    "        y = self.fpn(out)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d5d1c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = dict(num_channels=1, image_size=(96, 192, 192), num_stages=3, hidden_sizes=[80, 160, 320], depths=[3, 6, 3])\n",
    "#cfg = dict(num_channels=1, image_size=(96, 192, 192), num_stages=2, hidden_sizes=[40, 80])\n",
    "model = ConvNextV2BackbonewithFPN3D(cfg, returned_layers=[1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4ff9ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv3d(1, 80, kernel_size=(4, 4, 4), stride=(4, 4, 4))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.body.embeddings.patch_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e63eb21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_divisible = tuple(2 * s * 2 ** max([1, 2]) for s in model.body.embeddings.patch_embeddings.stride)\n",
    "size_divisible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e71a4a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNextV2BackbonewithFPN3D(\n",
       "  (body): ConvNextV2Model3d(\n",
       "    (embeddings): ConvNextV2Embeddings3d(\n",
       "      (patch_embeddings): Conv3d(1, 80, kernel_size=(4, 4, 4), stride=(4, 4, 4))\n",
       "      (layernorm): ConvNextV2LayerNorm3d()\n",
       "    )\n",
       "    (encoder): ConvNextV2Encoder3d(\n",
       "      (stages): ModuleList(\n",
       "        (0): ConvNextV2Stage3d(\n",
       "          (downsampling_layer): Identity()\n",
       "          (layers): Sequential(\n",
       "            (0): ConvNextV2Layer3d(\n",
       "              (dwconv): Conv3d(80, 80, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), groups=80)\n",
       "              (layernorm): ConvNextV2LayerNorm3d()\n",
       "              (pwconv1): Linear(in_features=80, out_features=320, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (grn): ConvNextV2GRN3d()\n",
       "              (pwconv2): Linear(in_features=320, out_features=80, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (1): ConvNextV2Layer3d(\n",
       "              (dwconv): Conv3d(80, 80, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), groups=80)\n",
       "              (layernorm): ConvNextV2LayerNorm3d()\n",
       "              (pwconv1): Linear(in_features=80, out_features=320, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (grn): ConvNextV2GRN3d()\n",
       "              (pwconv2): Linear(in_features=320, out_features=80, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (2): ConvNextV2Layer3d(\n",
       "              (dwconv): Conv3d(80, 80, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), groups=80)\n",
       "              (layernorm): ConvNextV2LayerNorm3d()\n",
       "              (pwconv1): Linear(in_features=80, out_features=320, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (grn): ConvNextV2GRN3d()\n",
       "              (pwconv2): Linear(in_features=320, out_features=80, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ConvNextV2Stage3d(\n",
       "          (downsampling_layer): Sequential(\n",
       "            (0): ConvNextV2LayerNorm3d()\n",
       "            (1): Conv3d(80, 160, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "          )\n",
       "          (layers): Sequential(\n",
       "            (0): ConvNextV2Layer3d(\n",
       "              (dwconv): Conv3d(160, 160, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), groups=160)\n",
       "              (layernorm): ConvNextV2LayerNorm3d()\n",
       "              (pwconv1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (grn): ConvNextV2GRN3d()\n",
       "              (pwconv2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (1): ConvNextV2Layer3d(\n",
       "              (dwconv): Conv3d(160, 160, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), groups=160)\n",
       "              (layernorm): ConvNextV2LayerNorm3d()\n",
       "              (pwconv1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (grn): ConvNextV2GRN3d()\n",
       "              (pwconv2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (2): ConvNextV2Layer3d(\n",
       "              (dwconv): Conv3d(160, 160, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), groups=160)\n",
       "              (layernorm): ConvNextV2LayerNorm3d()\n",
       "              (pwconv1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (grn): ConvNextV2GRN3d()\n",
       "              (pwconv2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (3): ConvNextV2Layer3d(\n",
       "              (dwconv): Conv3d(160, 160, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), groups=160)\n",
       "              (layernorm): ConvNextV2LayerNorm3d()\n",
       "              (pwconv1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (grn): ConvNextV2GRN3d()\n",
       "              (pwconv2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (4): ConvNextV2Layer3d(\n",
       "              (dwconv): Conv3d(160, 160, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), groups=160)\n",
       "              (layernorm): ConvNextV2LayerNorm3d()\n",
       "              (pwconv1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (grn): ConvNextV2GRN3d()\n",
       "              (pwconv2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (5): ConvNextV2Layer3d(\n",
       "              (dwconv): Conv3d(160, 160, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), groups=160)\n",
       "              (layernorm): ConvNextV2LayerNorm3d()\n",
       "              (pwconv1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (grn): ConvNextV2GRN3d()\n",
       "              (pwconv2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ConvNextV2Stage3d(\n",
       "          (downsampling_layer): Sequential(\n",
       "            (0): ConvNextV2LayerNorm3d()\n",
       "            (1): Conv3d(160, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "          )\n",
       "          (layers): Sequential(\n",
       "            (0): ConvNextV2Layer3d(\n",
       "              (dwconv): Conv3d(320, 320, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), groups=320)\n",
       "              (layernorm): ConvNextV2LayerNorm3d()\n",
       "              (pwconv1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (grn): ConvNextV2GRN3d()\n",
       "              (pwconv2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (1): ConvNextV2Layer3d(\n",
       "              (dwconv): Conv3d(320, 320, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), groups=320)\n",
       "              (layernorm): ConvNextV2LayerNorm3d()\n",
       "              (pwconv1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (grn): ConvNextV2GRN3d()\n",
       "              (pwconv2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (2): ConvNextV2Layer3d(\n",
       "              (dwconv): Conv3d(320, 320, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), groups=320)\n",
       "              (layernorm): ConvNextV2LayerNorm3d()\n",
       "              (pwconv1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (grn): ConvNextV2GRN3d()\n",
       "              (pwconv2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((320,), eps=1e-12, elementwise_affine=True)\n",
       "  )\n",
       "  (fpn): FeaturePyramidNetwork(\n",
       "    (inner_blocks): ModuleList(\n",
       "      (0): Conv3d(80, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "      (1): Conv3d(160, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "      (2): Conv3d(320, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    )\n",
       "    (layer_blocks): ModuleList(\n",
       "      (0-2): 3 x Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48009ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(torch.randn((1, 1, 96, 192, 192)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3cc7ab02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('layer1', torch.Size([1, 256, 24, 48, 48])),\n",
       " ('layer2', torch.Size([1, 256, 12, 24, 24])),\n",
       " ('layer3', torch.Size([1, 256, 6, 12, 12]))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(k, v.shape) for k, v in out.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01d702b",
   "metadata": {},
   "source": [
    "## Example-2 with extra_blocks=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf310083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('layer1', torch.Size([1, 256, 24, 48, 48])),\n",
       " ('layer2', torch.Size([1, 256, 12, 24, 24])),\n",
       " ('pool', torch.Size([1, 256, 6, 12, 12]))]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = dict(num_channels=1, image_size=(96, 192, 192), num_stages=2, hidden_sizes=[40, 80])\n",
    "model = ConvNextV2BackbonewithFPN3D(cfg, extra_blocks=True)\n",
    "out = model(torch.randn((1, 1, 96, 192, 192)))\n",
    "[(k, v.shape) for k, v in out.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8e1cdc",
   "metadata": {},
   "source": [
    "## Patch size is different in different dimensions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "894d2b3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('layer1', torch.Size([1, 256, 48, 48, 48])),\n",
       " ('layer2', torch.Size([1, 256, 24, 24, 24]))]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = dict(num_channels=1, image_size=(96, 192, 192), patch_size=(2, 4, 4), num_stages=2, hidden_sizes=[40, 80])\n",
    "model = ConvNextV2BackbonewithFPN3D(cfg, extra_blocks=False)\n",
    "out = model(torch.randn((1, 1, 96, 192, 192)))\n",
    "[(k, v.shape) for k, v in out.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76c71bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 32, 32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple(2 * s * 2 ** max([1, 2]) for s in model.body.embeddings.patch_embeddings.stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "35249deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpn_cfg = dict(\n",
    "    __class_fullname__ =\"voxdet.networks.convnextv2.ConvNextV2BackbonewithFPN3D\",\n",
    "    out_channels = 256,\n",
    "    returned_layers = [1, 2], #from backbone \n",
    "    extra_blocks = True)\n",
    "backbone_cfg = dict(num_channels=1, \n",
    "                    image_size=(96, 192, 192), \n",
    "                    patch_size=(2, 4, 4), \n",
    "                    num_stages=2, \n",
    "                    hidden_sizes=[40, 80])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255b462b",
   "metadata": {},
   "source": [
    "#TODO: size_divisible is pending "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8135ea9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from voxdet.utils import locate_cls\n",
    "fe = locate_cls(fpn_cfg, return_partial=True)(backbone_cfg=backbone_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f123c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNextV2BackbonewithFPN3D(\n",
       "  (body): ConvNextV2Model3d(\n",
       "    (embeddings): ConvNextV2Embeddings3d(\n",
       "      (patch_embeddings): Conv3d(1, 40, kernel_size=(2, 4, 4), stride=(2, 4, 4))\n",
       "      (layernorm): ConvNextV2LayerNorm3d()\n",
       "    )\n",
       "    (encoder): ConvNextV2Encoder3d(\n",
       "      (stages): ModuleList(\n",
       "        (0): ConvNextV2Stage3d(\n",
       "          (downsampling_layer): Identity()\n",
       "          (layers): Sequential(\n",
       "            (0): ConvNextV2Layer3d(\n",
       "              (dwconv): Conv3d(40, 40, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), groups=40)\n",
       "              (layernorm): ConvNextV2LayerNorm3d()\n",
       "              (pwconv1): Linear(in_features=40, out_features=160, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (grn): ConvNextV2GRN3d()\n",
       "              (pwconv2): Linear(in_features=160, out_features=40, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (1): ConvNextV2Layer3d(\n",
       "              (dwconv): Conv3d(40, 40, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), groups=40)\n",
       "              (layernorm): ConvNextV2LayerNorm3d()\n",
       "              (pwconv1): Linear(in_features=40, out_features=160, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (grn): ConvNextV2GRN3d()\n",
       "              (pwconv2): Linear(in_features=160, out_features=40, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (2): ConvNextV2Layer3d(\n",
       "              (dwconv): Conv3d(40, 40, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), groups=40)\n",
       "              (layernorm): ConvNextV2LayerNorm3d()\n",
       "              (pwconv1): Linear(in_features=40, out_features=160, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (grn): ConvNextV2GRN3d()\n",
       "              (pwconv2): Linear(in_features=160, out_features=40, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ConvNextV2Stage3d(\n",
       "          (downsampling_layer): Sequential(\n",
       "            (0): ConvNextV2LayerNorm3d()\n",
       "            (1): Conv3d(40, 80, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "          )\n",
       "          (layers): Sequential(\n",
       "            (0): ConvNextV2Layer3d(\n",
       "              (dwconv): Conv3d(80, 80, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), groups=80)\n",
       "              (layernorm): ConvNextV2LayerNorm3d()\n",
       "              (pwconv1): Linear(in_features=80, out_features=320, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (grn): ConvNextV2GRN3d()\n",
       "              (pwconv2): Linear(in_features=320, out_features=80, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (1): ConvNextV2Layer3d(\n",
       "              (dwconv): Conv3d(80, 80, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), groups=80)\n",
       "              (layernorm): ConvNextV2LayerNorm3d()\n",
       "              (pwconv1): Linear(in_features=80, out_features=320, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (grn): ConvNextV2GRN3d()\n",
       "              (pwconv2): Linear(in_features=320, out_features=80, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (2): ConvNextV2Layer3d(\n",
       "              (dwconv): Conv3d(80, 80, kernel_size=(7, 7, 7), stride=(1, 1, 1), padding=(3, 3, 3), groups=80)\n",
       "              (layernorm): ConvNextV2LayerNorm3d()\n",
       "              (pwconv1): Linear(in_features=80, out_features=320, bias=True)\n",
       "              (act): GELUActivation()\n",
       "              (grn): ConvNextV2GRN3d()\n",
       "              (pwconv2): Linear(in_features=320, out_features=80, bias=True)\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((80,), eps=1e-12, elementwise_affine=True)\n",
       "  )\n",
       "  (fpn): FeaturePyramidNetwork(\n",
       "    (inner_blocks): ModuleList(\n",
       "      (0): Conv3d(40, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "      (1): Conv3d(80, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    )\n",
       "    (layer_blocks): ModuleList(\n",
       "      (0-1): 2 x Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    )\n",
       "    (extra_blocks): LastLevelMaxPool(\n",
       "      (maxpool): MaxPool3d(kernel_size=1, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c51652aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qct_deep_clone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
