{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cace27e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0364e050",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afa55909",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "import torch\n",
    "from torchvision.transforms import Compose \n",
    "from voxdet.networks.monai_retina3d import retina_detector\n",
    "from munch import munchify\n",
    "from voxdet.bbox_func.nms import monai_nms\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e4aa619",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import numpy as np\n",
    "import fastcore.all as fc\n",
    "from pathlib import Path\n",
    "from IPython.display import Image as DisplayImage\n",
    "from voxdet.utils import hu_to_lung_window\n",
    "from voxdet.utils import vis, load_sitk_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9822615d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def subset_cfg_for_infer(cfg):\n",
    "    \"\"\"required transforms for spatial size\"\"\"\n",
    "    required = [\"anchor_params\", \"resolution\", \"classes\", \"spatial_size\", \"roi_size\", \"infer_cfg\", \\\n",
    "                \"infer_thr\", \"fe\", \"test_transforms\", \"fpn_params\", \"model_cfg\"]\n",
    "    cfg2 = {k:v for k, v in cfg.items() if k in required}\n",
    "    return cfg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52ee085c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def load_model(path, map_device=torch.device(\"cpu\")):\n",
    "    data = torch.load(path, map_location=map_device)\n",
    "    cfg = data[\"cfg\"]\n",
    "    cfg = munchify(cfg)\n",
    "\n",
    "    transforms = Compose([i for i in cfg.test_transforms])\n",
    "    model = retina_detector(cfg)\n",
    "    model.load_state_dict(data[\"state_dict\"], strict=False)\n",
    "    model = model.eval()\n",
    "    return model, cfg, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710dbb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = \"/cache/datanas1/qct-nodules/studies_nifti/WCG/1.3.6.1.4.1.55648.166786657465154199470575722567012949663.3.nii.gz\"\n",
    "series_id = series.rsplit(\"/\")[-1][:-7]\n",
    "oimg = load_sitk_img(series, series_id)\n",
    "oimg[\"images\"].shape, oimg[\"spacing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a333bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis(oimg[\"images\"], 64, window=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c1289e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "class RetinaInfer:\n",
    "    def __init__(self, checkpoint_path: str, device: str= None , inf_safe: bool =False):\n",
    "        self.model, self.cfg, self.transforms = load_model(path = checkpoint_path)\n",
    "        if device is None:\n",
    "            self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        else:\n",
    "            self.device = device\n",
    "        self.model.to(self.device)\n",
    "        self.inf_safe = inf_safe\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def __call__(self, img: dict, nms_thr=0.2, cnf_thr=0.05):\n",
    "        if not self.inf_safe : \n",
    "            nimg = self.transforms(img)\n",
    "        else :\n",
    "            nimg = img\n",
    "        \n",
    "        if len(nimg[\"images\"].shape) == 4:\n",
    "            input_image = torch.from_numpy(nimg[\"images\"]).type(torch.float32).to(self.device).unsqueeze(0)\n",
    "        else:\n",
    "            input_image = torch.from_numpy(nimg[\"images\"]).type(torch.float32).to(self.device).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "        logits = self.model(input_image, None, use_inferer=True)[0]  # hardcoded for one class\n",
    "        if nms_thr is not None: logits = monai_nms(logits, nms_thr, cnf_thr)\n",
    "        nimg.update(logits)\n",
    "        if self.inf_safe :\n",
    "            return nimg\n",
    "        nimg = self.reverse_apply(nimg)\n",
    "        return nimg\n",
    "    \n",
    "    def reverse_apply(self, img):\n",
    "        out = img.copy()\n",
    "        for tfsm in self.transforms.transforms[::-1]:\n",
    "            #import pdb; pdb.set_trace()\n",
    "            out = tfsm.reverse_apply(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6a3095",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DET = \"../lightning_logs/v150/version_6/checkpoints/epoch=224-step=22950-val/AP=0.638.ckpt\"\n",
    "infer = RetinaInfer(checkpoint_path=CHECKPOINT_DET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f66d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from voxdet.tfsm.med import AddLungCache\n",
    "infer.transforms.transforms.insert(1, AddLungCache(cache_dir=\"/cache/datanas1/qct-nodules/nifti_with_annots/lung_mask_cache/\",\\\n",
    "                                                       model_ckpt=\"/home/users/vanapalli.prakash/repos/qct_nodule_detection/resources/unet_r231-d5d2fc3d_v0.0.1.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2499d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer.transforms.transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c584d635",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"/cache/datanas1/qct-nodules/nifti_with_annots/medframe/\")\n",
    "series = fc.L(path.glob(\"*.nii.gz\"))\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c79fded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodules = []\n",
    "# for s_ in series:\n",
    "#     sp = path/(s_+\".nii.gz\")\n",
    "#     img = load_sitk_img(sp, s_)\n",
    "#     nimg = infer(img)\n",
    "#     nodules.append((s_, len(nimg[\"boxes\"][nimg[\"scores\"]>0.9])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4846f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "img = load_sitk_img(series[0], series[0].name[:-7])\n",
    "nimg = infer(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa2e68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nimg[\"lung_mask\"].shape, img[\"images\"].shape, nimg[\"images\"].shape, img[\"spacing\"], nimg[\"spacing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95d9b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "nimg[\"images\"].shape, nimg[\"boxes\"].shape, nimg[\"scores\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690f0ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from voxdet.retina_test import convert2int, draw_on_ct\n",
    "from qct_utils.ctvis.viewer import plot_scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb10139",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scans([nimg[\"images\"][0]], [\"scan\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f910a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nimg[\"images\"].shape, nimg[\"boxes\"].shape, nimg[\"scores\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7e2312",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c4ac10",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = convert2int(nimg[\"boxes\"][nimg[\"scores\"]>0.9])\n",
    "timg = img[\"images\"]\n",
    "dimg = draw_on_ct(timg, boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d74b96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522e5aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scans([dimg], [\"scan\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd18a134",
   "metadata": {},
   "outputs": [],
   "source": [
    "box = nimg[\"boxes\"][:10, :][7].astype(int)\n",
    "bimg = img[\"images\"][box[0]:box[3], box[1]-10:box[4]+10, box[2]-10:box[5]+10]\n",
    "bimg = np.uint8(hu_to_lung_window(bimg)*255)\n",
    "imageio.mimsave('sld_3.gif', [i for i in bimg])\n",
    "DisplayImage(data='sld_3.gif', width=180, height=180) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08e4417",
   "metadata": {},
   "outputs": [],
   "source": [
    "nimg[\"images\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bf601e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis(nimg[\"images\"]*255, 64, window=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e33cae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187c84c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
