task_name: fpr_mae
train: true
test: true
ckpt_path: null
seed: 12345
datamodule:
  transforms:
    val_transforms:
      _target_: monai.transforms.Compose
      transforms:
      - _target_: src.common.transforms.monai_extras.LoadSafeTensor
        image_key: image
      - _target_: src.common.transforms.monai_extras.ApplyWindowsChannelWise
        keys:
        - image
        windows:
        - LungA
    train_transforms:
      _target_: monai.transforms.Compose
      transforms:
      - _target_: src.common.transforms.monai_extras.LoadSafeTensor
        image_key: image
      - _target_: src.common.transforms.monai_extras.ApplyWindowsChannelWise
        keys:
        - image
        windows:
        - LungA
      - _target_: src.common.transforms.monai_extras.RandomHorizontalFlip
        keys:
        - image
        prob: 0.5
      - _target_: src.common.transforms.monai_extras.RandomGaussianBlur
        keys:
        - image
        kernel_size: 3
        sigma:
        - 0.1
        - 2.0
        prob: 0.5
  _target_: src.datamodules.base_dataloader.MetaClsDataModule
  data_cfg:
    data_extract_func: videomae_data_loader
    csvs:
    - /home/users/shubham.kumar/projects/qct_training_framework/notebooks/fpr_lidc.csv
    - /home/users/shubham.kumar/projects/qct_training_framework/notebooks/fpr_lidc_raw.csv
    - /home/users/shubham.kumar/projects/qct_training_framework/notebooks/fpr_nlst_pm_t0.csv
    - /home/users/shubham.kumar/projects/qct_training_framework/notebooks/fpr_nlst.csv
    directorys:
    - /cache/fast_data_nas8/qct/shubham/fpr_cache_48_48_16/safetensors_cache/
    - /cache/fast_data_nas8/qct/shubham/fpr_cache_lidc/
    - /cache/fast_data_nas8/qct/shubham/fpr_cache_nlst_pm_t0/
    - /cache/fast_data_nas8/qct/shubham/fpr_cache_nlst/
    frac: 1
    oversample_ratios: null
  dataloader_cfg:
    batch_size: 32
    num_workers: 16
    sample: false
    sample_fusion: false
model:
  optimizer:
    _target_: torch.optim.SGD
    _partial_: true
    lr: 0.1
    weight_decay: 0.0001
    momentum: 0.9
  scheduler:
    _target_: torch.optim.lr_scheduler.OneCycleLR
    _partial_: true
    max_lr: 0.5
    epochs: ${trainer.max_epochs}
  _target_: src.models.mae_module_copy.MAE3DModule
  model:
    _target_: src.common.nn_modules.nets.mae.mae3d.MAE3D
    pos_embed_type: sincos
    mask_ratio: 0.7
    input_size:
    - 48
    - 48
    - 16
    patch_size:
    - 4
    - 4
    - 2
    in_chans: 1
    encoder_embed_dim: 576
    encoder_depth: 6
    encoder_num_heads: 12
    decoder_embed_dim: 384
    decoder_depth: 4
    decoder_num_heads: 12
callbacks:
  model_checkpoint:
    _target_: lightning.pytorch.callbacks.ModelCheckpoint
    dirpath: ${paths.output_dir}/checkpoints
    filename: '{epoch}_{step}_{val_loss:.2f}'
    monitor: val_loss
    verbose: true
    save_last: true
    save_top_k: 2
    mode: min
    auto_insert_metric_name: true
    save_weights_only: false
    every_n_train_steps: null
    train_time_interval: null
    every_n_epochs: null
    save_on_train_epoch_end: null
  learning_rate_monitor:
    _target_: lightning.pytorch.callbacks.LearningRateMonitor
    logging_interval: step
  stochastic_weight_averaging:
    _target_: lightning.pytorch.callbacks.StochasticWeightAveraging
    swa_epoch_start: 0.67
    swa_lrs: 0.05
    annealing_epochs: 20
    annealing_strategy: cos
  rich_progress_bar:
    _target_: lightning.pytorch.callbacks.RichProgressBar
  model_summary:
    max_depth: 3
  pred_logger:
    num_samples: 4
    epoch_interval: 1
    log_gt_label: false
  early_stopping:
    monitor: val_loss
    patience: 30
    mode: min
logger:
  tensorboard:
    _target_: lightning.pytorch.loggers.tensorboard.TensorBoardLogger
    save_dir: ${paths.output_dir}/tensorboard/
    name: null
    log_graph: false
    default_hp_metric: true
    prefix: ''
trainer:
  _target_: lightning.pytorch.trainer.Trainer
  default_root_dir: ${paths.output_dir}
  min_epochs: 1
  max_epochs: 300
  accelerator: gpu
  devices:
  - 0
  - 1
  - 2
  log_every_n_steps: 1
  check_val_every_n_epoch: 1
  deterministic: false
  gradient_clip_val: 0.5
  gradient_clip_algorithm: norm
  accumulate_grad_batches: 16
  precision: 16-mixed
  num_sanity_val_steps: 0
  sync_batchnorm: true
paths:
  root_dir: ${oc.env:PROJECT_ROOT}
  data_dir: null
  log_dir: /data_nas5/qer/shubham/mae3d_checkpoints/
  output_dir: ${hydra:runtime.output_dir}
  work_dir: ${hydra:runtime.cwd}
extras:
  ignore_warnings: false
  enforce_tags: true
  print_config: true
skip_clearml: false
clearml_project: ${task_name}
clearml_task_name: fpr_mae3d_v16
tags:
- test
