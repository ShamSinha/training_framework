# @package _global_

# to execute this experiment run:
# python src/train.py experiment=nodule_classification

train: True # if true train the model
test: True # if true test the model
# if ckpt_path is not none and train is true: load the initial weight from the ckpt_path
# if ckpt_path is not none and train is false: test the model mentioned in ckpt_path
skip_clearml: False # in case it's a test experiment
ckpt_path:

defaults:
  - override /datamodule: nodule_classifiers_datamodule.yaml
  - override /model: nodule_classification
  - override /model/net/classification: deha_nets
  - override /model/criterion/classification: bi_tempered
  - _self_

task_name: training_framework_test

# Clearml project is created with ${clearml_project} and ${clearml_task_name} is the name present in experiments.qure.ai
clearml_project: ${task_name}
clearml_task_name: overfit # Keeping it mandatory for storing names

tags: ["dev"]

seed: 12345

## Data Module
# Add any key you want to overwrite.

## Lightning trainer
trainer: # Merge with default trainer mentioned above
  default_root_dir: ${paths.output_dir}
  # use "ddp_spawn" instead of "ddp",
  # it's slower but normal "ddp" currently doesn't work ideally with hydra
  # https://github.com/facebookresearch/hydra/issues/2070
  # https://pytorch-lightning.readthedocs.io/en/latest/accelerators/gpu_intermediate.html#distributed-data-parallel-spawn
  # strategy: ddp_spawn This is not working, can't figure out why. So keeping it on 1 GPU
  # devices: 2
  # num_nodes: 1
  accelerator: gpu
  min_epochs: 4
  max_epochs: 60
  gradient_clip_val: 0.5
  gradient_clip_algorithm: norm
  accumulate_grad_batches: 4
  precision: 16
  sync_batchnorm: True
  track_grad_norm: 2

## Lighning callbacks
callbacks: # Merged with defaults mentioned in callbacks/default.yaml
  model_checkpoint:
    dirpath: ${paths.output_dir}/checkpoints
    filename: "{epoch}_{step}_{val/epoch_auc_ovo:.4f}"
    monitor: "val/epoch_auc_ovo" # using val/dice has some weird behaviour while saving checkpoint. It is stored as dir val/dice
    mode: "max"
    save_last: True
    auto_insert_metric_name: True
    save_top_k: 5
    verbose: true

  early_stopping:
    monitor: "val/epoch_auc_ovo"
    patience: 30
    mode: "max"

  model_summary:
    max_depth: 2

  ClsSubAnalysis:
    subgroups_keys: [z_spacing, volume, Texture, Calcification, Spiculation]

  stochastic_weight_averaging:
    swa_epoch_start: 1 # Make this 1 to turn this off.
    swa_lrs: 0.05
    annealing_epochs: 20

## Defining paths
paths:
  # path to root directory
  # this requires PROJECT_ROOT environment variable to exist
  # PROJECT_ROOT is inferred and set by pyrootutils package in `train.py` and `eval.py`
  root_dir: ${oc.env:PROJECT_ROOT}

  # path to data directory, No data directory is being used.
  data_dir: null

  # path to logging directory
  log_dir: /home/users/souvik.mandal/datasets/model_checkpoints/training

  # path to output directory, created dynamically by hydra
  # path generation pattern is specified in `configs/hydra/default.yaml`
  # use it to store all files generated during the run, like ckpts and metrics
  # defaults to this log_dir/task_name
  output_dir: ${hydra:runtime.output_dir}

  # path to working directory
  work_dir: ${hydra:runtime.cwd}
