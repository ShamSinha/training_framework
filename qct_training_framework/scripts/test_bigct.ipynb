{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Uses the predictions from the detection model to get the segm predictions. tested against following packages.\n",
    "\n",
    "```python\n",
    "qct_data: 0.2.10\n",
    "qct_utils: 2.0.3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrootutils\n",
    "\n",
    "root = pyrootutils.setup_root(\n",
    "    search_from=\"\",\n",
    "    indicator=[\".git\", \"pyproject.toml\"],\n",
    "    pythonpath=True,\n",
    "    dotenv=True,\n",
    ")\n",
    "\n",
    "import json\n",
    "import os\n",
    "from typing import Any, Optional\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import torch\n",
    "from qct_data.ct_loader import CTAnnotLoader\n",
    "from qct_utils.ct_schema import ITKDIM, BigCtscan, Ctscan\n",
    "from qct_utils.ctscan_dataloaders.utils import read_annotation_csvs\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.apps.segmentation_infer import NoduleSegmInfer\n",
    "from src.metrics.segmentation.tp_metrics import TPMetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test against BigCT output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"segm_qnet_8820.ckpt\"\n",
    "gt_annot_csv = [\n",
    "    \"/home/users/souvik.mandal/projects/qct/qct_data_updates/data/studies/FDA/WCG/wcg_s1_s2_gt.csv\"\n",
    "]\n",
    "pred_bigct_json_root = (\n",
    "    \"/home/users/souvik.mandal/projects/qct/qct_meta_training_framework/data/bigct_tmp\"\n",
    ")\n",
    "scans_root = (\n",
    "    \"/home/users/souvik.mandal/projects/qct/qct_data_updates/data/studies/FDA/WCG/data_tmp\"\n",
    ")\n",
    "det_thr = 0.7  # there are too many nodules without threshold, Keep it `None` for no theresholding\n",
    "new_bigct_save_root = (\n",
    "    \"/home/users/souvik.mandal/projects/qct/qct_meta_training_framework/data/wcg/model8820_post\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df = read_annotation_csvs(gt_annot_csv)\n",
    "len(\n",
    "    gt_df.scan_name.unique()\n",
    ")  # we will only use these many sids since remaining scans are FP predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "considered_series_ids = gt_df.scan_name.unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update the segmentation masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. If we have the new model integrated with prod we dont need to run the below code.\n",
    "2. Following section will get the bbox from the bigctjson and infer with the new model and save the new results to another folder.\n",
    "3. If u have a large number of datapoints copy the below code and run in a tmux script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "segmentation_infer = NoduleSegmInfer(ckpt_path=ckpt_path, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(path: str):\n",
    "    with open(path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "\n",
    "def dump_json(data: Any, save_path: str):\n",
    "    with open(save_path, \"w\") as not_file:\n",
    "        json.dump(data, not_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bigct(\n",
    "    big_ct_root: str,\n",
    "    sid: str,\n",
    "    scans_root: str,\n",
    "    det_thr: Optional[float] = None,\n",
    "    load_scan: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Load bigct from json and if the scan is missing add the scan\n",
    "    \"\"\"\n",
    "    big_ct_path = os.path.join(big_ct_root, f\"{sid}_bigct.json\")\n",
    "    big_ct = load_json(big_ct_path)\n",
    "    pred_ct = BigCtscan(**big_ct).Pred\n",
    "    if pred_ct.Scan is None and load_scan:\n",
    "        scan = sitk.GetArrayFromImage(sitk.ReadImage(os.path.join(scans_root, f\"{sid}.nii.gz\")))\n",
    "        pred_ct.Scan = scan\n",
    "    if det_thr is not None:\n",
    "        pred_ct.Annot = [annot for annot in pred_ct.Annot if annot.annot.conf > det_thr]\n",
    "    return pred_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_bigct(ctscan: Ctscan, save_root: str):\n",
    "    \"\"\"\n",
    "    Save a ctscan with new segmentation output to bigct output format\n",
    "    \"\"\"\n",
    "    sid = ctscan.SeriesInstanceUID\n",
    "    save_path = os.path.join(save_root, f\"{sid}_bigct.json\")\n",
    "    big_ct_dict = BigCtscan(Pred=ctscan).dict()\n",
    "    dump_json(big_ct_dict, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment if we need to update the bigct results from prod\n",
    "\n",
    "# for sid in tqdm(considered_series_ids[:5]):\n",
    "#     pred_ct = load_bigct(big_ct_root=pred_bigct_json_root, sid=sid, scans_root = scans_root, det_thr=det_thr)\n",
    "#     new_pred_ct = segmentation_infer.predict_ctscan(pred_ct, crop_margin=ITKDIM(z=15, x=80, y=80), roi_margin=ITKDIM(z=5, y=20, x=20), conf_thr=0.5, volume_thr=0)\n",
    "#     export_bigct(new_pred_ct, new_bigct_save_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model output performance\n",
    "1. Will use the `new_bigct_save_root` to get the pred bigct jsons and `gt_annot_csv` to get the ground truth annotations.\n",
    "2. Only computes the performance on the TP nodules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_annot_loader = CTAnnotLoader(scans_root=scans_root, csv_loc=gt_annot_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = TPMetrics(match_annots=True)\n",
    "\n",
    "for sid in tqdm(considered_series_ids[:10]):\n",
    "    gt_ctscan = gt_annot_loader[sid]\n",
    "    pred_ctscan = load_bigct(\n",
    "        big_ct_root=new_bigct_save_root, sid=sid, scans_root=\"\", det_thr=None, load_scan=False\n",
    "    )\n",
    "    metric.update(pred_ctscans=[pred_ctscan], gt_ctscans=[gt_ctscan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference on single series and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference on single ctscan\n",
    "from copy import deepcopy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from qct_utils.ct_vis.scan_vis import ctscan_to_df_pretty, vis_ctscan_annots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_id = \"1.3.6.1.4.1.55648.0105750886814768212503752621247817.4\"\n",
    "pred_ctscan = load_bigct(pred_bigct_json_root, series_id, scans_root, det_thr=0.7, load_scan=True)\n",
    "gt_ctscan = gt_annot_loader[series_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pred_ct = segmentation_infer.predict_ctscan(\n",
    "    deepcopy(gt_ctscan),\n",
    "    crop_margin=ITKDIM(z=15, x=80, y=80),\n",
    "    roi_margin=ITKDIM(z=5, y=20, x=20),\n",
    "    conf_thr=0.5,\n",
    "    volume_thr=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = ctscan_to_df_pretty(gt_ctscan)\n",
    "tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pred_ct.Annot[0].annot.mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_new_pred_scan = vis_ctscan_annots(new_pred_ct)\n",
    "annotated_old_pred_scan = vis_ctscan_annots(pred_ctscan)\n",
    "annotated_gt_scan = vis_ctscan_annots(gt_ctscan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1\n",
    "y_start = int(tdf.iloc[index][\"y_center\"]) - 50\n",
    "x_start = int(tdf.iloc[index][\"x_center\"]) - 50\n",
    "for index in range(\n",
    "    int(tdf.iloc[index][\"z_center\"] - 3 - tdf.iloc[index][\"d\"] / 2),\n",
    "    int(tdf.iloc[index][\"z_center\"] + 3 + tdf.iloc[index][\"d\"] / 2),\n",
    "):\n",
    "    plt.figure(index)\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(\n",
    "        annotated_new_pred_scan[\"scan\"][index, y_start : y_start + 100, x_start : x_start + 100]\n",
    "    )\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(\n",
    "        annotated_old_pred_scan[\"scan\"][index, y_start : y_start + 100, x_start : x_start + 100]\n",
    "    )\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(annotated_gt_scan[\"scan\"][index, y_start : y_start + 100, x_start : x_start + 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "820fc1f2b736e4f35723a5f818317f7f4fd14ba5e56683c944c3daf254b7918b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.15 ('training')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
