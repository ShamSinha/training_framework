defaults:
  # - cls: cls_tb
  # - seg: seg_tb
  # - files: e2e
  # - model/optimizer: adam
  # - model/scheduler: one_cycle_lr
  - override hydra/hydra_logging: disabled #prevent logging
  - override hydra/job_logging: disabled #prevent logging
  - _self_

#prevent logging
hydra:
  output_subdir: null
  run:
    dir: .

path:
  checkpoint_dir: "/fast_data_e2e11/qxr_ln_trainings/checkpoints"
  checkpoint_path: ""
  log_directory: "/fast_data_e2e11/qxr_ln_trainings/logs"

cls: 
  sampling_tags: ['nodule']
  heads: ['nodule']
  user_class_wts:  {'nodule': 3.1254740435873964, 'regular_border': 4.120448567451853 , 'irregular_border': 5.3393107873337255, 'homogenous': 5.289269720598228 , 'inhomogenous': 5.30327400405999, 'normal': 1.0, 'nota': 1.0703267513043493}
  loss_wts : { 'nodule' : 3.570616706311101, 
    'regular_border' : 4.707299528704338 , 
    'irregular_border': 6.0997570388651505 , 
    'homogenous': 6.0425889208820385 , 
    'inhomogenous': 6.058587751071711 , 
    'normal': 1.0 }
  alpha: 2

seg:
  sampling_tags: ['nodule']
  heads: ['nodule']
  dice_threshold: [0.35, 0.35, 0.35, 0.35, 0.35] 
  user_class_wts: {'nodule': 1.0, 'regular_border': 1.0, 'irregular_border': 1.0, 'homogenous': 1.0, 'inhomogenous': 1.0} 
  loss_wts: { 'nodule' : 1.0,
    'regular_border' : 1.3183435568382738, 
    'irregular_border' : 1.7083203100696214, 
    'homogenous' : 1.692309597443406, 
    'inhomogenous': 1.6967902884572001}
  alpha: 5

files:   
  # testing_csv: '/fast_data_e2e11/qxr_ln_trainings/testing/nlst_jsrt.csv'
  # testing_images:  ['/fast_data_e2e_1/cxr/qxr_ln_data/jsrt_nlst/data'  ]
  # testing_annotation_path: ['/fast_data_e2e_1/cxr/qxr_ln_data/jsrt_nlst/masks']  ##giving a dummy path for now to avoid error
  testing_csv: '/fast_data_e2e_1/cxr/qxr_ln_data/LN_test/combined_test_csv_updated_internal_test_13-08-24.csv'
  testing_images:  ['/fast_data_e2e_1/cxr/qxr_ln_data/padchest/pngs/pngs_1440/', '/fast_data_e2e_1/cxr/qxr_ln_data/segmed/segmed_pngs/', '/fast_data_e2e_1/cxr/qxr_ln_data/sbri/pngs/', '/fast_data_e2e_1/cxr/qxr_ln_data/vrad_imgs/' , '/fast_data_e2e_1/cxr/qxr_ln_data/jsrt_nlst/data/', '/fast_data_e2e_1/cxr/qxr_ln_data/mgh/all_pngs/' , '/fast_data_e2e_1/cxr/qxr_ln_data/fda_data/nodule_fda/', '/models_common_e2e/cxr_data/testing/images/']
  testing_annotation_path: ['/models_common_e2e/cxr_data/testing/test_annotations']  ## doing seg analysis only on internal test - have to generate for bot h fda/nlstjsrt

model:
  __target__: cxr_training.nnmodule.nnmodule_controller.LitModel
  encoder_library: timm
  encoder: swinv2_tiny_window8_256
  decoder: unetplusplus
  in_channels: 1
  out_channels: 2
  scheduler:
    _target_: torch.optim.lr_scheduler.OneCycleLR
    params:
      pct_start: 0.3
      max_lr: 0.0005
      anneal_strategy: 'cos'
      div_factor: 250 #self.max_lr / self.optimizer_lr
      final_div_factor: 100 # self.optimizer_lr / self.final_lr
      base_momentum: 0.90 # momentum changes beta[0] value in adamw
      max_momentum: 0.95
      three_phase: False
  optimizer:
    _target_: torch.optim.AdamW
    params:
      lr: 0.0005
      betas: [0.9, 0.99]
      eps: 1e-08
      weight_decay: 0.1

trainer:
    description: "base_training"
    project: "qxr_ln_training"
    model_file: "23_aug_swin_tiny_full_data_ch_usr_wgt"
    batch_size: 32
    num_workers: 4
    gpus: [-1]
    recipe: "testing"
    recipe_module: cxr_training.recipes.test_recipe.TestRecipe
    checkpoint_dir: "/fast_data_e2e11/qxr_ln_trainings/checkpoints"
    model_list: ['model_556-epoch=82-val_loss=9.069142.ckpt', 'model_556-epoch=76-val_loss=9.067122.ckpt']

params:
    im_size: 1024
    f1_beta_value:
    inference_on_subset: False
    inference_on_images: False
    inference_type: "cls_seg"
    metric_type: "cls_seg"
    inference_run: True
    metric_run: True

use_clearml: False
validate_config: False











