## modified nota weights chanegd model changed seg - loss weights  and user  class weights acc to masks available , cls/seg =1/3
defaults:
  # - cls: cls_tb
  # - seg: seg_tb
  # - files: e2e
  # - model/optimizer: adama
  # - model/scheduler: one_cycle_lr
  - override hydra/hydra_logging: disabled #prevent logging
  - override hydra/job_logging: disabled #prevent logging
  - _self_

#prevent logging
hydra:
  output_subdir: null
  run:
    dir: .

path:
  checkpoint_dir: "/raid/qxr_ln_trainings/checkpoints"
  checkpoint_path: ""
  log_directory: "/raid/qxr_ln_trainings/logs"


cls:
    sampling_tags: [ 'nodule', 'normal', 'homogenous', 'inhomogenous','solitary', 'diffuse', 'regular_border', 'irregular_border','tinynodule', 'calcified', 'cancer', 'large' ,'nota']
    heads: [ 'nodule', 'normal', 'homogenous', 'inhomogenous','solitary', 'diffuse', 'regular_border', 'irregular_border','tinynodule', 'calcified', 'cancer', 'large']
    user_class_wts: {'homogenous': 1.0, 'diffuse': 1.0, 'nodule': 1.0, 'regular_border': 1.0,'large': 1.0,'calcified': 1.0,'tinynodule': 1.0,'solitary': 1.0,'inhomogenous': 1.0, 'nota': 2.0, 'cancer': 1.0, 'irregular_border': 1.0, 'normal': 1.0}
    loss_wts : {'nodule': 3.1812369897695034, 'normal': 1.0, 'homogenous': 9.947599187414783, 'inhomogenous': 4.025962370058834, 'solitary': 3.894152237517562, 'diffuse': 6.914762585083279, 'regular_border': 5.427531826620126, 'irregular_border': 4.545327028131693, 'tinynodule': 5.654952022782779, 'calcified': 7.89527267821774, 'cancer': 4.729926247732154, 'large': 4.720442253178729}
    alpha: 1

seg:
    sampling_tags: ['nodule'] #, 'homogenous', 'inhomogenous','solitary', 'diffuse', 'regular_border', 'irregular_border','tinynodule', 'calcified', 'cancer', 'large']
    heads: ['nodule'] #, 'homogenous', 'inhomogenous','solitary', 'diffuse', 'regular_border', 'irregular_border','tinynodule', 'calcified', 'cancer', 'large']
    dice_threshold: [0.35] #, 0.35, 0.35, 0.35, 0.35, 0.35, 0.35, 0.35, 0.35, 0.35, 0.35]
    user_class_wts : {'nodule': 1.0} #,'homogenous': 3.0584352044346037, 'inhomogenous': 2.180750249846104, 'solitary': 2.004999800060938, 'diffuse': 2.22415092024277, 'regular_border': 1.6503408397101482, 'irregular_border': 4.266820059475632, 'tinynodule': 1.7383141731869858, 'calcified': 2.3293561814588957, 'cancer': 7.2221423843056565, 'large': 7.185574339824003}
    loss_wts : {'nodule': 1.0} #, 'homogenous': 3.0584352044346037, 'inhomogenous': 2.180750249846104, 'solitary': 2.004999800060938, 'diffuse': 2.22415092024277, 'regular_border': 1.6503408397101482, 'irregular_border': 4.266820059475632, 'tinynodule': 1.7383141731869858, 'calcified': 2.3293561814588957, 'cancer': 7.2221423843056565, 'large': 7.185574339824003}
    alpha: 3.0


files:
  ground_truth_csv: '/raid/piyush/training/training_csvs/old_train_data_1.8M.csv'
  img_folder_path:  ['/raid/cxr_data/training/images/']
  annotation_path: ['/raid/cxr_data/training/annotations/lms_annotations']


model:
  __target__: cxr_training.nnmodule.nnmodule_controller.LitModel
  encoder_library: smp
  encoder: tu-efficientnet_b5
  decoder: unet
  in_channels: 1
  out_channels: 2
  scheduler:
    _target_: torch.optim.lr_scheduler.OneCycleLR
    params:
      pct_start: 0.3
      max_lr: 0.2
      anneal_strategy: cos
      div_factor: 25
      steps_per_epoch: 1,
      epochs: initial_stage_epochs
  optimizer:
    _target_: torch.optim.SGD
    params:
      lr: 0.2
      weight_decay: 0.0001


trainer:
  description: base_training
  project: qxr_ln_training
  model_file: 5_sept_effecientnetb5_unet_old_data_manoj_lr_0.2_nodule_seg
  check_gradients: false
  recipe_module: cxr_training.recipes.base_recipe.BaseRecipe
  recipe: cls_seg
  total_epochs: 200
  accumulate_grad_batches: 30
  strategy: ddp
  batch_size: 8
  precision: 16
  num_workers: 8
  train_samples: 15000
  validation_samples: 4000
  gpus: [0,1,2,3]
  fast_dev_run: false
params:
  data_loader: cxr_training.data.dataloader.base_dataloader.DataModule
  dataset_type: cxr_training.data.datasets.cls_seg_dataset.Base_dataset
  metric_type: default
  im_size: 1024
  loss_type: dice-bce
  sources: []
  equal_source_sampling: false
  mask_threshold: 0.2
  use_real_fake_sampling: true
  real_data_wts: 0.7
  use_3d_2d_fake_data_sampling: False
  data_weights_3d: 0.3
  sampler: train_weighted_val_random


use_clearml: True
validate_config: False