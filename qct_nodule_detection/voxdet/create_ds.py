# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/05a_create_safetensors.ipynb.

# %% auto 0
__all__ = ['ctscan2dict', 'fixed_cache_transforms', 'generate_cache']

# %% ../nbs/05a_create_safetensors.ipynb 3
import torch
import pandas as pd
import numpy as np 
import fastcore.all as fc 

from loguru import logger
from typing import Optional
from safetensors.numpy import save_file
from qct_utils.ctscan.ct_loader import CTAnnotLoader

# %% ../nbs/05a_create_safetensors.ipynb 26
def ctscan2dict(ctscan):
    file = {}
    spacing = ctscan.scan.spacing
    file["series_id"] = ctscan.series_instance_uid
    file["images"] = ctscan.scan.array.astype(np.int16)
    file["boxes"] =  np.empty((0, 6)) if len(ctscan.nodules) == 0 else np.asarray([i.gt.annot.bbox.xcyczcwhd for i in  ctscan.nodules])[:, [1, 0, 2, 4, 3, 5]]
    if np.any(file["boxes"]<0): breakpoint()
    file["labels"] = np.zeros(file["boxes"].shape[0]).astype(np.int8)
    file["spacing"] = np.asarray([spacing.z, spacing.y, spacing.x])
    return file

# %% ../nbs/05a_create_safetensors.ipynb 27
def fixed_cache_transforms(lung_cache_dir: str = "", 
                           device: str="cuda:0",
                            roi: Optional[str] = None):
    from voxdet.utils import locate_cls
    from torchvision.transforms import Compose
    test_transforms = [
    dict(__class_fullname__ = "voxdet.tfsm.standard.StandardT",
         src_mode="yxzhwd", 
         img_src_mode="zyx"),
    dict(__class_fullname__="voxdet.tfsm.med.AddLungCache", 
         cache_dir=lung_cache_dir,
        device = device), 
    dict(__class_fullname__="voxdet.tfsm.med.CropLung",
         device = device,
        roi = roi),
    ]
    transforms = Compose([locate_cls(i) for i in test_transforms])
    return transforms 

# %% ../nbs/05a_create_safetensors.ipynb 30
def generate_cache(meta_root, csv_loc, transforms, save_dir_root):
    tfsm = transforms
    df = pd.read_csv(csv_loc)
    df = df.rename(columns = {"annot_union" : "annot" , "meta_union": "meta"})
    df = df.sort_values(by='scan_name')
    df['counter'] = df.groupby('scan_name').cumcount() + 1
    df['annot_id'] = df['scan_name'] + "_" + df['counter'].astype(str)
    df.drop(columns=['counter'], inplace=True)
    
    series_ids = fc.L(df.scan_name.unique().tolist())

    ds = CTAnnotLoader(scans_root=meta_root, csv_loc=df, series_ids=series_ids)
    fc.Path(save_dir_root).mkdir(exist_ok=True)
    for n, sid in enumerate(series_ids):
        save_path = fc.Path(save_dir_root)/f"{sid}.safetensors"
        if save_path.exists(): 
            logger.info(f"{n}-{sid} already exists")
            continue
        try : 
            ctscan = ds[sid]
        except:
            logger.debug(f"scan is not present for this {sid}")
            continue
        for annot in ctscan.nodules:
            annot.gt.annot.bbox = annot.gt.annot.mask.to_boxc()
            logger.debug(annot.gt.annot.bbox)

        file = ctscan2dict(ctscan)

        rads = []
        for att in ctscan.nodules : 
            rads.append(df.loc[df["annot_id"] == att.gt.annot_id , "rads"].values[0])

        file["rads"] = np.asarray(rads)
        
        try:
            file2 = tfsm(file)

            if np.any(file2["boxes"]<0): 
                logger.info(f"failed: {sid}")
                continue
            logger.info(f"{n}-{sid}-{file['boxes'].shape[0]}")

            file2["images"]=file2["images"].astype(np.int16)
            del file2["lung_mask"] #delete lung mask it is not required.
            del file2["series_id"] # delete series_id as we are saving the file with series_id.

            save_file(file2, save_path)
        
        except Exception as e :
            logger.error(e)
            continue
